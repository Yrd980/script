<div align="center"> <p align="center"> <img src="asset/uniposelogo.png" width="250px"> </p> <h2> X-Pose: Detecting Any Keypoints </h2> !PWChttps://paperswithcode.com/sota/2d-human-pose-estimation-on-human-art?p=unipose-detecting-any-keypoints !PWChttps://paperswithcode.com/sota/2d-pose-estimation-on-animal-kingdom?p=unipose-detecting-any-keypoints !PWChttps://paperswithcode.com/sota/2d-pose-estimation-on-300w?p=unipose-detecting-any-keypoints !PWChttps://paperswithcode.com/sota/2d-pose-estimation-on-macaquepose?p=unipose-detecting-any-keypoints !PWChttps://paperswithcode.com/sota/2d-pose-estimation-on-desert-locust?p=unipose-detecting-any-keypoints !PWChttps://paperswithcode.com/sota/2d-pose-estimation-on-vinegar-fly?p=unipose-detecting-any-keypoints !PWChttps://paperswithcode.com/sota/multi-person-pose-estimation-on-coco?p=unipose-detecting-any-keypoints !PWChttps://paperswithcode.com/sota/animal-pose-estimation-on-ap-10k?p=unipose-detecting-any-keypoints Online demo:!Open in OpenXLabhttps://openxlab.org.cn/apps/detail/IDEA-Research/IDEA Quick Checkpoint download:!Open in OpenXLabhttps://openxlab.org.cn/models/detail/IDEA-Research/UniPose <code>Project Page</code> | <code>Paper</code> | <code>UniKPT Dataset</code> |<code>Video</code> Jie Yang<sup>1,2</sup>, Ailing Zeng<sup>1</sup>, Ruimao Zhang<sup>2</sup>, Lei Zhang<sup>1</sup> <sup>1</sup>International Digital Economy Academy <sup>2</sup>The Chinese University of Hong Kong, Shenzhen </div> ðŸ¤© News - 2024.07.12: X-Pose supports controllable animal face animation. See details here. <img src="asset/xpose-liveportrait.gif" style="height:150px" /> - 2024.07.02: X-Pose is accepted to ECCV24 We changed the model name from UniPose to X-Pose to avoid confusion with similarly named previous works. - 2024.02.14: We update a file to highlight all classes 1237 classes in the UNIKPT dataset. - 2023.11.28: We are excited to highlight the 68 face keypoints detection ability of X-Pose across any categories in this figure. The definition of face keypoints follows this dataset. - 2023.11.9: Thanks to OpenXLab, you can try a quick online demo. Looking forward to the feedback! - 2023.11.1: We release the inference code, demo, checkpoints, and the annotation of the UniKPT dataset. - 2023.10.13: We release the arxiv version. In-the-wild Test via X-Pose X-Pose has strong fine-grained localization and generalization abilities across image styles, categories, and poses. <p align="middle"> <img src="asset/in-the-wild.jpg" width="2000"> <br> </p> Detecting any Face Keypoints: <p align="middle"> <img src="asset/anyface.png" width="2000"> <br> </p> ðŸ—’ TODO - x Release inference code and demo. - x Release checkpoints. - x Release UniKPT annotations. - Release training codes. ðŸ’¡ Overview â€¢ X-Pose is the first end-to-end prompt-based keypoint detection framework. <p align="middle"> <img src="asset/framework.png" width="2000"> <br> </p> â€¢ It supports multi-modality prompts, including textual and visual prompts to detect arbitrary keypoints e.g., from articulated, rigid, and soft objects. Visual Prompts as Inputs: <p align="middle"> <img src="asset/task1.png" width="2000"> <br> </p> Textual Prompts as Inputs: <p align="middle"> <img src="asset/task2.png" width="2000"> <br> </p> ðŸ”¨ Environment Setup 1. Clone this repo 2. Install the needed packages 3. Compiling CUDA operators â–¶ Demo 1. Guidelines â€¢ We have released the textual prompt-based branch for inference. As the visual prompt involves a substantial amount of user input, we are currently exploring more user-friendly platforms to support this functionality. â€¢ Since X-Pose has learned strong structural prior, it's best to use the predefined skeleton as the keypoint textual prompts, which are shown in predefinedkeypoints.py. â€¢ If users don't provide a keypoint prompt, we'll try to match the appropriate skeleton based on the user's instance category. If unsuccessful, we'll default to using the animal's skeleton, which covers a wider range of categories and testing requirements. 2. Run Replace , , and with appropriate values in the following command We also support the inference using gradio. Checkpoints <!-- insert a table --> <table> <thead> <tr style="text-align: center;"> <th></th> <th>name</th> <th>backbone</th> <th>Keypoint AP on COCO</th> <th>Checkpoint</th> <th>Config</th> </tr> </thead> <tbody> <tr style="text-align: center;"> <th>1</th> <td>X-Pose</td> <td>Swin-T</td> <td>74.4</td> <td><a href="https://drive.google.com/file/d/13gANvGWyWApMFTAtC3ntrMgx0fOocjIa/view"> Google Drive</a> /<a href="https://openxlab.org.cn/models/detail/IDEA-Research/UniPose"> OpenXLab</a> <td><a href="https://github.com/IDEA-Research/UniPose/blob/master/configmodel/UniPoseSwinT.py">GitHub Link</a></td> </tr> </tbody> <tbody> <tr style="text-align: center;"> <th>2</th> <td>X-Pose</td> <td>Swin-L</td> <td>76.8</td> <td> Coming Soon</td> <td> Coming Soon</td> </tr> </tbody> </table> The UniKPT Dataset <p align="middle"> <img src="asset/dataset.png" width="2000"> <br> </p> | Datasets | KPT | Class | Images | Instances | Unify Images | Unify Instance | |----------------------------------------------------------------------------------------------------------------------------------------------------------|---------|-------|--------|----------------------|---------------|----------------| | COCO | 17 | 1 | 58,945| 156,165 | 58,945 | 156,165 | | 300W-Face | 68 | 1 | 3,837| 4,437 | 3,837 | 4,437 | | OneHand10K | 21 | 1 |11,703| 11,289 | 2,000 | 2000 | | Human-Art | 17 | 1 | 50,000| 123,131 | 50,000 | 123,131 | | AP-10K | 17 | 54 | 10,015| 13,028 | 10,015 | 13,028 | | APT-36K | 17 | 30 | 36,000| 53,006 | 36,000 | 53,006 | | MacaquePose | 17 | 1 | 13,083| 16,393 | 2,000 | 2,320 | | Animal Kingdom | 23 | 850 | 33,099| 33,099 | 33,099 | 33,099 | | AnimalWeb | 9 | 332 | 22,451 | 21,921 | 22,451 | 21,921 | | Vinegar Fly | 31 | 1 |1,500| 1,500 | 1,500 | 1,500 | | Desert Locust | 34 | 1 | 700| 700 | 700 | 700 | | Keypoint-5 | 55/31 | 5 | 8,649| 8,649 | 2,000 | 2,000 | | MP-100 | 561/293 | 100 | 16,943 | 18,000 | 16,943 | 18,000 | | UniKPT | 338 | 1237 | - | - | 226,547 | 418,487 | â€¢ UniKPT is a unified dataset from 13 existing datasets, which is only for non-commercial research purposes. â€¢ All images included in the UniKPT dataset originate from the datasets listed in the table above. To access these images, please download them from the original repository. â€¢ We provide the annotations with precise keypoints' textual descriptions for effective training. More conveniently, you can find the text annotations in the link. Citing X-Pose If you find this repository useful for your work, please consider citing it as follows: