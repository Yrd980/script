<h1 align="center"> ğŸ¦‰ OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation </h1> <div align="center"> !Documentationdocs-imagedocs-url !Discorddiscord-imagediscord-url !Xx-imagex-url !Redditreddit-imagereddit-url !Wechatwechat-imagewechat-url !Wechatowl-imageowl-url !Hugging Facehuggingface-imagehuggingface-url !Starstar-imagestar-url !Package Licensepackage-license-imagepackage-license-url </div> <hr> <div align="center" style="background-color: e3f2fd; padding: 20px; border-radius: 15px; border: 3px solid 1976d2; margin: 25px 0;"> <h2 style="color: 1976d2; margin: 0 0 15px 0; font-size: 1.8em;"> ğŸš€ <b>Introducing Eigent: The World's First Multi-Agent Workforce Desktop Application</b> ğŸš€ </h2> <p style="font-size: 1.2em; margin: 10px 0; line-height: 1.6;"> <b>Eigent</b> empowers you to build, manage, and deploy a custom AI workforce that can turn your most complex workflows into automated tasks. </p> <p style="font-size: 1.1em; margin: 15px 0;"> âœ¨ <b>100% Open Source</b> â€¢ ğŸ”§ <b>Fully Customizable</b> â€¢ ğŸ”’ <b>Privacy-First</b> â€¢ âš¡ <b>Parallel Execution</b> </p> <p style="font-size: 1em; margin: 15px 0; font-style: italic;"> Built on CAMEL-AI's acclaimed open-source project, Eigent introduces a Multi-Agent Workforce that boosts productivity through parallel execution, customization, and privacy protection. </p> <div style="margin-top: 20px;"> <a href="https://github.com/eigent-ai/eigent" style="background-color: d81b60; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold; margin: 0 5px;">ğŸ”— Visit Eigent Repo</a> <a href="https://www.eigent.ai/" style="background-color: 1976d2; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold; margin: 0 5px;">Learn More</a> <a href="https://www.eigent.ai/download" style="background-color: 43a047; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold; margin: 0 5px;">Get Started</a> </div> </div> <hr> <div align="center"> <h4 align="center"> ä¸­æ–‡é˜…è¯» | Community | Installation | Examples | Paper | <!-- Technical Report | --> Citation | Contributing | CAMEL-AI </h4> <div align="center" style="background-color: f0f7ff; padding: 10px; border-radius: 5px; margin: 15px 0;"> <h3 style="color: 1e88e5; margin: 0;"> ğŸ† OWL achieves <span style="color: d81b60; font-weight: bold; font-size: 1.2em;">69.09</span> average score on GAIA benchmark and ranks <span style="color: d81b60; font-weight: bold; font-size: 1.2em;">ğŸ…ï¸ 1</span> among open-source frameworks! ğŸ† </h3> </div> <div align="center"> ğŸ¦‰ OWL is a cutting-edge framework for multi-agent collaboration that pushes the boundaries of task automation, built on top of the CAMEL-AI Framework. <!-- OWL achieves 58.18 average score on GAIA benchmark and ranks ğŸ…ï¸ 1 among open-source frameworks. --> Our vision is to revolutionize how AI agents collaborate to solve real-world tasks. By leveraging dynamic agent interactions, OWL enables more natural, efficient, and robust task automation across diverse domains. </div> !./assets/owlarchitecture.png <br> </div> <!-- Key Features --> ğŸ“‹ Table of Contents - ğŸ“‹ Table of Contents - ğŸš€ Eigent: Multi-Agent Workforce Desktop Application - ğŸ”¥ News - ğŸ¬ Demo Video - âœ¨ï¸ Core Features - ğŸ› ï¸ Installation - Prerequisites - Install Python - Installation Options - Option 1: Using uv Recommended - Option 2: Using venv and pip - Option 3: Using conda - Option 4: Using Docker - Using Pre-built Image Recommended - Building Image Locally - Using Convenience Scripts - Setup Environment Variables - Setting Environment Variables Directly - Alternative: Using a File - MCP Desktop Commander Setup - ğŸš€ Quick Start - Basic Usage - Running with Different Models - Model Requirements - Supported Models - Example Tasks - ğŸ§° Toolkits and Capabilities - Model Context Protocol MCP - Install Node.js - Windows - Linux - Mac - Install Playwright MCP Service - Available Toolkits - Available Toolkits - Multimodal Toolkits Require multimodal model capabilities - Text-Based Toolkits - Customizing Your Configuration - ğŸŒ Web Interface - Starting the Web UI - Features - ğŸ§ª Experiments - â±ï¸ Future Plans - ğŸ“„ License - ğŸ¤ Contributing - ğŸ”¥ Community - â“ FAQ - General Questions - Experiment Questions - ğŸ“š Exploring CAMEL Dependency - Accessing CAMEL Source Code - ğŸ–Šï¸ Cite - â­ Star History ğŸš€ Eigent: Multi-Agent Workforce Desktop Application <div align="center" style="background-color: f5f5f5; padding: 20px; border-radius: 10px; margin: 20px 0;"> Eigent is revolutionizing the way we work with AI agents. As the world's first Multi-Agent Workforce desktop application, Eigent transforms complex workflows into automated, intelligent processes. Why Eigent? - ğŸ¤– Multi-Agent Collaboration: Deploy multiple specialized AI agents that work together seamlessly - ğŸš€ Parallel Execution: Boost productivity with agents that can work on multiple tasks simultaneously - ğŸ¨ Full Customization: Build and configure your AI workforce to match your specific needs - ğŸ”’ Privacy-First Design: Your data stays on your machine - no cloud dependencies required - ğŸ’¯ 100% Open Source: Complete transparency and community-driven development Key Capabilities - Build Custom Workflows: Design complex multi-step processes that agents can execute autonomously - Manage AI Teams: Orchestrate multiple agents with different specializations working in concert - Deploy Instantly: From idea to execution in minutes, not hours - Monitor Progress: Real-time visibility into agent activities and task completion Use Cases - ğŸ“Š Data Analysis: Automate complex data processing and analysis workflows - ğŸ” Research: Deploy agents to gather, synthesize, and report on information - ğŸ’» Development: Accelerate coding tasks with AI-powered development teams - ğŸ“ Content Creation: Generate, edit, and optimize content at scale - ğŸ¤ Business Automation: Transform repetitive business processes into automated workflows Get Started with Eigent Eigent is built on top of the OWL framework, leveraging CAMEL-AI's powerful multi-agent capabilities. ğŸ”— Visit the Eigent Repository to explore the codebase, contribute, or learn more about building your own AI workforce. Follow our installation guide to start building your own AI workforce today! </div> ğŸ”¥ News <div align="center" style="background-color: e8f5e9; padding: 15px; border-radius: 10px; border: 2px solid 4caf50; margin: 20px 0;"> <h3 style="color: 2e7d32; margin: 0; font-size: 1.3em;"> ğŸ§© <b>NEW: COMMUNITY AGENT CHALLENGES!</b> ğŸ§© </h3> <p style="font-size: 1.1em; margin: 10px 0;"> Showcase your creativity by designing unique challenges for AI agents! <br> Join our community and see your innovative ideas tackled by cutting-edge AI. </p> <p> <a href="https://github.com/camel-ai/owl/blob/main/communitychallenges.md" style="background-color: 2e7d32; color: white; padding: 8px 15px; text-decoration: none; border-radius: 5px; font-weight: bold;">View & Submit Challenges</a> </p> </div> <div style="background-color: e3f2fd; padding: 12px; border-radius: 8px; border-left: 4px solid 1e88e5; margin: 10px 0;"> <h4 style="color: 1e88e5; margin: 0 0 8px 0;"> ğŸ‰ Latest Major Update - March 15, 2025 </h4> <p style="margin: 0;"> <b>Significant Improvements:</b> <ul style="margin: 5px 0 0 0; padding-left: 20px;"> <li>Restructured web-based UI architecture for enhanced stability ğŸ—ï¸</li> <li>Optimized OWL Agent execution mechanisms for better performance ğŸš€</li> </ul> <i>Try it now and experience the improved performance in your automation tasks!</i> </p> </div> - 2025.07.21: We open-sourced the training dataset and model checkpoints of OWL project. Training code coming soon. huggingface link. - 2025.05.27: We released the technical report of OWL, including more details on the workforce framework and optimized workforce learning training methodology. paper. - 2025.05.18: We open-sourced an initial version for replicating workforce experiment on GAIA here. - 2025.04.18: We uploaded OWL's new GAIA benchmark score of 69.09%, ranking 1 among open-source frameworks. Check the technical report here. - 2025.03.27: Integrate SearxNGToolkit performing web searches using SearxNG search engine. - 2025.03.26: Enhanced Browser Toolkit with multi-browser support for "chrome", "msedge", and "chromium" channels. - 2025.03.25: Supported Gemini 2.5 Pro, added example run code - 2025.03.21: Integrated OpenRouter model platform, fix bug with Gemini tool calling. - 2025.03.20: Accept header in MCP Toolkit, support automatic playwright installation. - 2025.03.16: Support Bing search, Baidu search. - 2025.03.12: Added Bocha search in SearchToolkit, integrated Volcano Engine model platform, and enhanced Azure and OpenAI Compatible models with structured output and tool calling. - 2025.03.11: We added MCPToolkit, FileWriteToolkit, and TerminalToolkit to enhance OWL agents with MCP tool calling, file writing capabilities, and terminal command execution. - 2025.03.09: We added a web-based user interface that makes it easier to interact with the system. - 2025.03.07: We open-sourced the codebase of the ğŸ¦‰ OWL project. - 2025.03.03: OWL achieved the 1 position among open-source frameworks on the GAIA benchmark with a score of 58.18. ğŸ¬ Demo Video https://github.com/user-attachments/assets/2a2a825d-39ea-45c5-9ba1-f9d58efbc372 https://private-user-images.githubusercontent.com/55657767/420212194-e813fc05-136a-485f-8df3-f10d9b4e63ec.mp4 This video demonstrates how to install OWL locally and showcases its capabilities as a cutting-edge framework for multi-agent collaboration: https://www.youtube.com/watch?v=8XlqVyAZOr8 âœ¨ï¸ Core Features - Online Search: Support for multiple search engines including Wikipedia, Google, DuckDuckGo, Baidu, Bocha, etc. for real-time information retrieval and knowledge acquisition. - Multimodal Processing: Support for handling internet or local videos, images, and audio data. - Browser Automation: Utilize the Playwright framework for simulating browser interactions, including scrolling, clicking, input handling, downloading, navigation, and more. - Document Parsing: Extract content from Word, Excel, PDF, and PowerPoint files, converting them into text or Markdown format. - Code Execution: Write and execute Python code using interpreter. - Built-in Toolkits: Access to a comprehensive set of built-in toolkits including: - Model Context Protocol MCP: A universal protocol layer that standardizes AI model interactions with various tools and data sources - Core Toolkits: ArxivToolkit, AudioAnalysisToolkit, CodeExecutionToolkit, DalleToolkit, DataCommonsToolkit, ExcelToolkit, GitHubToolkit, GoogleMapsToolkit, GoogleScholarToolkit, ImageAnalysisToolkit, MathToolkit, NetworkXToolkit, NotionToolkit, OpenAPIToolkit, RedditToolkit, SearchToolkit, SemanticScholarToolkit, SymPyToolkit, VideoAnalysisToolkit, WeatherToolkit, BrowserToolkit, and many more for specialized tasks ğŸ› ï¸ Installation Prerequisites Install Python Before installing OWL, ensure you have Python installed version 3.10, 3.11, or 3.12 is supported: > Note for GAIA Benchmark Users: When running the GAIA benchmark evaluation, please use the branch which includes a customized version of the CAMEL framework in the directory. This version contains enhanced toolkits with improved stability specifically optimized for the GAIA benchmark compared to the standard CAMEL installation. Installation Options OWL supports multiple installation methods to fit your workflow preferences. Option 1: Using uv Recommended Option 2: Using venv and pip Option 3: Using conda Option 4: Using Docker Using Pre-built Image Recommended Building Image Locally Using Convenience Scripts Setup Environment Variables OWL requires various API keys to interact with different services. Setting Environment Variables Directly You can set environment variables directly in your terminal: - macOS/Linux Bash/Zsh: - Windows Command Prompt: - Windows PowerShell: > Note: Environment variables set directly in the terminal will only persist for the current session. Alternative: Using a File If you prefer using a file instead, you can: 1. Copy and Rename the Template: Alternatively, you can manually create a new file named in the owl directory and copy the contents from . 2. Configure Your API Keys: Open the file in your preferred text editor and insert your API keys in the corresponding fields. > Note: For the minimal example , you only need to configure the LLM API key e.g., . MCP Desktop Commander Setup If using MCP Desktop Commander within Docker, run: For more detailed Docker usage instructions, including cross-platform support, optimized configurations, and troubleshooting, please refer to DOCKERREADME.md. ğŸš€ Quick Start Basic Usage After installation and setting up your environment variables, you can start using OWL right away: Running with Different Models Model Requirements - Tool Calling: OWL requires models with robust tool calling capabilities to interact with various toolkits. Models must be able to understand tool descriptions, generate appropriate tool calls, and process tool outputs. - Multimodal Understanding: For tasks involving web interaction, image analysis, or video processing, models with multimodal capabilities are required to interpret visual content and context. Supported Models For information on configuring AI models, please refer to our CAMEL models documentation. > Note: For optimal performance, we strongly recommend using OpenAI models GPT-4 or later versions. Our experiments show that other models may result in significantly lower performance on complex tasks and benchmarks, especially those requiring advanced multi-modal understanding and tool use. OWL supports various LLM backends, though capabilities may vary depending on the model's tool calling and multimodal abilities. You can use the following scripts to run with different models: For a simpler version that only requires an LLM API key, you can try our minimal example: You can run OWL agent with your own task by modifying the script: For uploading files, simply provide the file path along with your question: OWL will then automatically invoke document-related tools to process the file and extract the answer. Example Tasks Here are some tasks you can try with OWL: - "Find the latest stock price for Apple Inc." - "Analyze the sentiment of recent tweets about climate change" - "Help me debug this Python code: your code here" - "Summarize the main points from this research paper: paper URL" - "Create a data visualization for this dataset: dataset path" ğŸ§° Toolkits and Capabilities Model Context Protocol MCP OWL's MCP integration provides a standardized way for AI models to interact with various tools and data sources: Before using MCP, you need to install Node.js first. Install Node.js Windows Download the official installer: Node.js. Check "Add to PATH" option during installation. Linux Mac Install Playwright MCP Service Try our comprehensive MCP examples: - - Basic MCP functionality demonstration local call, requires dependencies - - Example using the SSE protocol Use remote services, no dependencies Available Toolkits > Important: Effective use of toolkits requires models with strong tool calling capabilities. For multimodal toolkits Web, Image, Video, models must also have multimodal understanding abilities. OWL supports various toolkits that can be customized by modifying the list in your script: Available Toolkits Key toolkits include: Multimodal Toolkits Require multimodal model capabilities - BrowserToolkit: Browser automation for web interaction and navigation - VideoAnalysisToolkit: Video processing and content analysis - ImageAnalysisToolkit: Image analysis and interpretation Text-Based Toolkits - AudioAnalysisToolkit: Audio processing requires OpenAI API - CodeExecutionToolkit: Python code execution and evaluation - SearchToolkit: Web searches Google, DuckDuckGo, Wikipedia - DocumentProcessingToolkit: Document parsing PDF, DOCX, etc. Additional specialized toolkits: ArxivToolkit, GitHubToolkit, GoogleMapsToolkit, MathToolkit, NetworkXToolkit, NotionToolkit, RedditToolkit, WeatherToolkit, and more. For a complete list, see the CAMEL toolkits documentation. Customizing Your Configuration To customize available tools: Selecting only necessary toolkits optimizes performance and reduces resource usage. ğŸŒ Web Interface <div align="center" style="background-color: f0f7ff; padding: 15px; border-radius: 10px; border: 2px solid 1e88e5; margin: 20px 0;"> <h3 style="color: 1e88e5; margin: 0;"> ğŸš€ Enhanced Web Interface Now Available! </h3> <p style="margin: 10px 0;"> Experience improved system stability and optimized performance with our latest update. Start exploring the power of OWL through our user-friendly interface! </p> </div> Starting the Web UI Features - Easy Model Selection: Choose between different models OpenAI, Qwen, DeepSeek, etc. - Environment Variable Management: Configure your API keys and other settings directly from the UI - Interactive Chat Interface: Communicate with OWL agents through a user-friendly interface - Task History: View the history and results of your interactions The web interface is built using Gradio and runs locally on your machine. No data is sent to external servers beyond what's required for the model API calls you configure. ğŸ§ª Experiments To reproduce OWL's GAIA benchmark score: Furthermore, to ensure optimal performance on the GAIA benchmark, please note that our branch includes a customized version of the CAMEL framework in the directory. This version contains enhanced toolkits with improved stability for gaia benchmark compared to the standard CAMEL installation. When running the benchmark evaluation: 1. Switch to the branch: 2. Run the evaluation script: This will execute the same configuration that achieved our top-ranking performance on the GAIA benchmark. â±ï¸ Future Plans We're continuously working to improve OWL. Here's what's on our roadmap: - x Write a technical blog post detailing our exploration and insights in multi-agent collaboration in real-world tasks - x Enhance the toolkit ecosystem with more specialized tools for domain-specific tasks - x Develop more sophisticated agent interaction patterns and communication protocols - x Improve performance on complex multi-step reasoning tasks ğŸ“„ License The source code is licensed under Apache 2.0. ğŸ¤ Contributing We welcome contributions from the community! Here's how you can help: 1. Read our Contribution Guidelines 2. Check open issues or create new ones 3. Submit pull requests with your improvements Current Issues Open for Contribution: - 1915 - 2190 - 2165 - 2121 - 1908 - 1538 - 1481 To take on an issue, simply leave a comment stating your interest. ğŸ”¥ Community Join us Discord or WeChat in pushing the boundaries of finding the scaling laws of agents. Join us for further discussions! <!-- !./assets/community.png --> !./assets/communitycode.jpeg â“ FAQ General Questions Q: Why don't I see Chrome running locally after starting the example script? A: If OWL determines that a task can be completed using non-browser tools such as search or code execution, the browser will not be launched. The browser window will only appear when OWL determines that browser-based interaction is necessary. Q: Which Python version should I use? A: OWL supports Python 3.10, 3.11, and 3.12. Q: How can I contribute to the project? A: See our Contributing section for details on how to get involved. We welcome contributions of all kinds, from code improvements to documentation updates. Experiment Questions Q: Which CAMEL version should I use for replicate the role playing result? A: We provide a modified version of CAMEL owl/camel in the gaia58.18 branch. Please make sure you use this CAMEL version for your experiments. Q: Why are my experiment results lower than the reported numbers? A: Since the GAIA benchmark evaluates LLM agents in a realistic world, it introduces a significant amount of randomness. Based on user feedback, one of the most common issues for replication is, for example, agents being blocked on certain webpages due to network reasons. We have uploaded a keywords matching script to help quickly filter out these errors here. You can also check this technical report for more details when evaluating LLM agents in realistic open-world environments. ğŸ“š Exploring CAMEL Dependency OWL is built on top of the CAMEL Framework, here's how you can explore the CAMEL source code and understand how it works with OWL: Accessing CAMEL Source Code ğŸ–Šï¸ Cite If you find this repo useful, please cite: â­ Star History !Star History Charthttps://star-history.com/camel-ai/owl&Date docs-image: https://img.shields.io/badge/Documentation-EB3ECC docs-url: https://camel-ai.github.io/camel/index.html star-image: https://img.shields.io/github/stars/camel-ai/owl?label=stars&logo=github&color=brightgreen star-url: https://github.com/camel-ai/owl/stargazers package-license-image: https://img.shields.io/badge/License-Apache2.0-blue.svg package-license-url: https://github.com/camel-ai/owl/blob/main/licenses/LICENSE colab-url: https://colab.research.google.com/drive/1AzP33O8rnMW7ocWJhVBXjKziJXPtim?usp=sharing colab-image: https://colab.research.google.com/assets/colab-badge.svg huggingface-url: https://huggingface.co/camel-ai huggingface-image: https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-CAMEL--AI-ffc107?color=ffc107&logoColor=white discord-url: https://discord.camel-ai.org/ discord-image: https://img.shields.io/discord/1082486657678311454?logo=discord&labelColor=%20%235462eb&logoColor=%20%23f5f5f5&color=%20%235462eb wechat-url: https://ghli.org/camel/wechat.png wechat-image: https://img.shields.io/badge/WeChat-CamelAIOrg-brightgreen?logo=wechat&logoColor=white x-url: https://x.com/CamelAIOrg x-image: https://img.shields.io/twitter/follow/CamelAIOrg?style=social twitter-image: https://img.shields.io/twitter/follow/CamelAIOrg?style=social&color=brightgreen&logo=twitter reddit-url: https://www.reddit.com/r/CamelAI/ reddit-image: https://img.shields.io/reddit/subreddit-subscribers/CamelAI?style=plastic&logo=reddit&label=r%2FCAMEL&labelColor=white ambassador-url: https://www.camel-ai.org/community owl-url: ./assets/qrcode.jpg owl-image: https://img.shields.io/badge/WeChat-OWLProject-brightgreen?logo=wechat&logoColor=white