> !NOTE > Aug 14 Webinar - OpenAI's gpt-oss: Separating the Substance from the Hype. Places limited! !Oumi Logo !Documentationhttps://oumi.ai/docs/en/latest/index.html !Bloghttps://oumi.ai/blog !Twitterhttps://x.com/OumiPBC !Discordhttps://discord.gg/oumi !PyPI versionhttps://badge.fury.io/py/oumi !Licensehttps://opensource.org/licenses/Apache-2.0 !Testshttps://github.com/oumi-ai/oumi/actions/workflows/pretest.yaml !GPU Testshttps://github.com/oumi-ai/oumi/actions/workflows/gputests.yaml !GitHub Repo starshttps://github.com/oumi-ai/oumi/stargazers !Code style: blackhttps://github.com/psf/black !pre-commithttps://github.com/pre-commit/pre-commit !Abouthttps://oumi.ai Everything you need to build state-of-the-art foundation models, end-to-end. <p align="center"> <a href="https://trendshift.io/repositories/12865"> <img alt="GitHub trending" src="https://trendshift.io/api/badge/repositories/12865" /> </a> </p> üî• News - 2025/08 Aug 14 Webinar - OpenAI's gpt-oss: Separating the Substance from the Hype. Places limited! - 2025/08 Oumi v0.3.0 released with model quantization AWQ, an improved LLM-as-a-Judge API, and Adaptive Inference - 2025/07 Recipe for Qwen3 235B - 2025/07 July 24 webinar: "Training a State-of-the-art Agent LLM with Oumi + Lambda" - 2025/06 Oumi v0.2.0 released with support for GRPO fine-tuning, a plethora of new model support, and much more - 2025/06 Announcement of Data Curation for Vision Language Models DCVLR competition at NeurIPS2025 - 2025/06 Recipes for training, inference, and eval with the newly released Falcon-H1 and Falcon-E models - 2025/05 Support and recipes for InternVL3 1B - 2025/04 Added support for training and inference with Llama 4 models: Scout 17B activated, 109B total and Maverick 17B activated, 400B total variants, including full fine-tuning, LoRA, and QLoRA configurations - 2025/04 Recipes for Qwen3 model family - 2025/04 Introducing HallOumi: a State-of-the-Art Claim-Verification Model technical overview - 2025/04 Oumi now supports two new Vision-Language models: Phi4 and Qwen 2.5 üîé About Oumi is a fully open-source platform that streamlines the entire lifecycle of foundation models - from data preparation and training to evaluation and deployment. Whether you're developing on a laptop, launching large scale experiments on a cluster, or deploying models in production, Oumi provides the tools and workflows you need. With Oumi, you can: - üöÄ Train and fine-tune models from 10M to 405B parameters using state-of-the-art techniques SFT, LoRA, QLoRA, DPO, and more - ü§ñ Work with both text and multimodal models Llama, DeepSeek, Qwen, Phi, and others - üîÑ Synthesize and curate training data with LLM judges - ‚ö°Ô∏è Deploy models efficiently with popular inference engines vLLM, SGLang - üìä Evaluate models comprehensively across standard benchmarks - üåé Run anywhere - from laptops to clusters to clouds AWS, Azure, GCP, Lambda, and more - üîå Integrate with both open models and commercial APIs OpenAI, Anthropic, Vertex AI, Together, Parasail, ... All with one consistent API, production-grade reliability, and all the flexibility you need for research. Learn more at oumi.ai, or jump right in with the quickstart guide. üöÄ Getting Started | Notebook | Try in Colab | Goal | |----------|--------------|-------------| | üéØ Getting Started: A Tour | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - A Tour.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Quick tour of core features: training, evaluation, inference, and job management | | üîß Model Finetuning Guide | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Finetuning Tutorial.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | End-to-end guide to LoRA tuning with data prep, training, and evaluation | | üìö Model Distillation | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Distill a Large Model.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Guide to distilling large models into smaller, efficient ones | | üìã Model Evaluation | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Evaluation with Oumi.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Comprehensive model evaluation using Oumi's evaluation framework | | ‚òÅÔ∏è Remote Training | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Running Jobs Remotely.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Launch and monitor training jobs on cloud AWS, Azure, GCP, Lambda, etc. platforms | | üìà LLM-as-a-Judge | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Simple Judge.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Filter and curate training data with built-in judges | üîß Usage Installation Installing oumi in your environment is straightforward: For more advanced installation options, see the installation guide. Oumi CLI You can quickly use the command to train, evaluate, and infer models using one of the existing recipes: For more advanced options, see the training, evaluation, inference, and llm-as-a-judge guides. Running Jobs Remotely You can run jobs remotely on cloud platforms AWS, Azure, GCP, Lambda, etc. using the command: Note: Oumi is in <ins>beta</ins> and under active development. The core features are stable, but some advanced features might change as the platform improves. üíª Why use Oumi? If you need a comprehensive platform for training, evaluating, or deploying models, Oumi is a great choice. Here are some of the key features that make Oumi stand out: - üîß Zero Boilerplate: Get started in minutes with ready-to-use recipes for popular models and workflows. No need to write training loops or data pipelines. - üè¢ Enterprise-Grade: Built and validated by teams training models at scale - üéØ Research Ready: Perfect for ML research with easily reproducible experiments, and flexible interfaces for customizing each component. - üåê Broad Model Support: Works with most popular model architectures - from tiny models to the largest ones, text-only to multimodal. - üöÄ SOTA Performance: Native support for distributed training techniques FSDP, DDP and optimized inference engines vLLM, SGLang. - ü§ù Community First: 100% open source with an active community. No vendor lock-in, no strings attached. üìö Examples & Recipes Explore the growing collection of ready-to-use configurations for state-of-the-art models and training workflows: Note: These configurations are not an exhaustive list of what's supported, simply examples to get you started. You can find a more exhaustive list of supported models, and datasets supervised fine-tuning, pre-training, preference tuning, and vision-language finetuning in the oumi documentation. Qwen Family | Model | Example Configurations | |-------|------------------------| | Qwen3 30B A3B | LoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | | Qwen3 32B | LoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | | QwQ 32B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | | Qwen2.5-VL 3B | SFT ‚Ä¢ LoRA‚Ä¢ Inference vLLM ‚Ä¢ Inference | | Qwen2-VL 2B | SFT ‚Ä¢ LoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference SGLang ‚Ä¢ Inference ‚Ä¢ Evaluation | üêã DeepSeek R1 Family | Model | Example Configurations | |-------|------------------------| | DeepSeek R1 671B | Inference Together AI | | Distilled Llama 8B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | | Distilled Llama 70B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | | Distilled Qwen 1.5B | FFT ‚Ä¢ LoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | | Distilled Qwen 32B | LoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | ü¶ô Llama Family | Model | Example Configurations | |-------|------------------------| | Llama 4 Scout Instruct 17B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference ‚Ä¢ Inference Together.ai | | Llama 4 Scout 17B | FFT | | Llama 3.1 8B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Pre-training ‚Ä¢ Inference vLLM ‚Ä¢ Inference ‚Ä¢ Evaluation | | Llama 3.1 70B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference ‚Ä¢ Evaluation | | Llama 3.1 405B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA | | Llama 3.2 1B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference SGLang ‚Ä¢ Inference ‚Ä¢ Evaluation | | Llama 3.2 3B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference SGLang ‚Ä¢ Inference ‚Ä¢ Evaluation | | Llama 3.3 70B | FFT ‚Ä¢ LoRA ‚Ä¢ QLoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference ‚Ä¢ Evaluation | | Llama 3.2 Vision 11B | SFT ‚Ä¢ Inference vLLM ‚Ä¢ Inference SGLang ‚Ä¢ Evaluation | ü¶Ö Falcon family | Model | Example Configurations | |-------|------------------------| | Falcon-H1 | FFT ‚Ä¢ Inference ‚Ä¢ Evaluation | | Falcon-E BitNet | FFT ‚Ä¢ DPO ‚Ä¢ Evaluation | üé® Vision Models | Model | Example Configurations | |-------|------------------------| | Llama 3.2 Vision 11B | SFT ‚Ä¢ LoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference SGLang ‚Ä¢ Evaluation | | LLaVA 7B | SFT ‚Ä¢ Inference vLLM ‚Ä¢ Inference | | Phi3 Vision 4.2B | SFT ‚Ä¢ LoRA ‚Ä¢ Inference vLLM | | Phi4 Vision 5.6B | SFT ‚Ä¢ LoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference | | Qwen2-VL 2B | SFT ‚Ä¢ LoRA ‚Ä¢ Inference vLLM ‚Ä¢ Inference SGLang ‚Ä¢ Inference ‚Ä¢ Evaluation | | Qwen2.5-VL 3B | SFT ‚Ä¢ LoRA‚Ä¢ Inference vLLM ‚Ä¢ Inference | | SmolVLM-Instruct 2B | SFT ‚Ä¢ LoRA | üîç Even more options This section lists all the language models that can be used with Oumi. Thanks to the integration with the ü§ó Transformers library, you can easily use any of these models for training, evaluation, or inference. Models prefixed with a checkmark ‚úÖ have been thoroughly tested and validated by the Oumi community, with ready-to-use recipes available in the configs/recipes directory. <details> <summary>üìã Click to see more supported models</summary> Instruct Models | Model | Size | Paper | HF Hub | License | Open ^1 | Recommended Parameters | |-------|------|-------|---------|----------|------|------------------------| | ‚úÖ SmolLM-Instruct | 135M/360M/1.7B | Blog | Hub | Apache 2.0 | ‚úÖ | | | ‚úÖ DeepSeek R1 Family | 1.5B/8B/32B/70B/671B | Blog | Hub | MIT | ‚ùå | | | ‚úÖ Llama 3.1 Instruct | 8B/70B/405B | Paper | Hub | License | ‚ùå | | | ‚úÖ Llama 3.2 Instruct | 1B/3B | Paper | Hub | License | ‚ùå | | | ‚úÖ Llama 3.3 Instruct | 70B | Paper | Hub | License | ‚ùå | | | ‚úÖ Phi-3.5-Instruct | 4B/14B | Paper | Hub | License | ‚ùå | | | Qwen2.5-Instruct | 0.5B-70B | Paper | Hub | License | ‚ùå | | | OLMo 2 Instruct | 7B | Paper | Hub | Apache 2.0 | ‚úÖ | | | MPT-Instruct | 7B | Blog | Hub | Apache 2.0 | ‚úÖ | | | Command R | 35B/104B | Blog | Hub | License | ‚ùå | | | Granite-3.1-Instruct | 2B/8B | Paper | Hub | Apache 2.0 | ‚ùå | | | Gemma 2 Instruct | 2B/9B | Blog | Hub | License | ‚ùå | | | DBRX-Instruct | 130B MoE | Blog | Hub | Apache 2.0 | ‚ùå | | | Falcon-Instruct | 7B/40B | Paper | Hub | Apache 2.0 | ‚ùå | | | ‚úÖ Llama 4 Scout Instruct | 17B Activated 109B Total | Paper | Hub | License | ‚ùå | | | ‚úÖ Llama 4 Maverick Instruct | 17B Activated 400B Total | Paper | Hub | License | ‚ùå | | Vision-Language Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | ‚úÖ Llama 3.2 Vision | 11B | Paper | Hub | License | ‚ùå | | | ‚úÖ LLaVA-1.5 | 7B | Paper | Hub | License | ‚ùå | | | ‚úÖ Phi-3 Vision | 4.2B | Paper | Hub | License | ‚ùå | | | ‚úÖ BLIP-2 | 3.6B | Paper | Hub | MIT | ‚ùå | | | ‚úÖ Qwen2-VL | 2B | Blog | Hub | License | ‚ùå | | | ‚úÖ SmolVLM-Instruct | 2B | Blog | Hub | Apache 2.0 | ‚úÖ | | Base Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | ‚úÖ SmolLM2 | 135M/360M/1.7B | Blog | Hub | Apache 2.0 | ‚úÖ | | | ‚úÖ Llama 3.2 | 1B/3B | Paper | Hub | License | ‚ùå | | | ‚úÖ Llama 3.1 | 8B/70B/405B | Paper | Hub | License | ‚ùå | | | ‚úÖ GPT-2 | 124M-1.5B | Paper | Hub | MIT | ‚úÖ | | | DeepSeek V2 | 7B/13B | Blog | Hub | License | ‚ùå | | | Gemma2 | 2B/9B | Blog | Hub | License | ‚ùå | | | GPT-J | 6B | Blog | Hub | Apache 2.0 | ‚úÖ | | | GPT-NeoX | 20B | Paper | Hub | Apache 2.0 | ‚úÖ | | | Mistral | 7B | Paper | Hub | Apache 2.0 | ‚ùå | | | Mixtral | 8x7B/8x22B | Blog | Hub | Apache 2.0 | ‚ùå | | | MPT | 7B | Blog | Hub | Apache 2.0 | ‚úÖ | | | OLMo | 1B/7B | Paper | Hub | Apache 2.0 | ‚úÖ | | | ‚úÖ Llama 4 Scout | 17B Activated 109B Total | Paper | Hub | License | ‚ùå | | Reasoning Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | Qwen QwQ | 32B | Blog | Hub | License | ‚úÖ | | Code Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | ‚úÖ Qwen2.5 Coder | 0.5B-32B | Blog | Hub | License | ‚ùå | | | DeepSeek Coder | 1.3B-33B | Paper | Hub | License | ‚ùå | | | StarCoder 2 | 3B/7B/15B | Paper | Hub | License | ‚úÖ | | Math Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | DeepSeek Math | 7B | Paper | Hub | License | ‚ùå | | </details> üìñ Documentation To learn more about all the platform's capabilities, see the Oumi documentation. ü§ù Join the Community! Oumi is a community-first effort. Whether you are a developer, a researcher, or a non-technical user, all contributions are very welcome! - To contribute to the repository, please check the https://github.com/oumi-ai/oumi/blob/main/CONTRIBUTING.md for guidance on how to contribute to send your first Pull Request. - Make sure to join our Discord community to get help, share your experiences, and contribute to the project! - If you are interested in joining one of the community's open-science efforts, check out our open collaboration page. üôè Acknowledgements Oumi makes use of several libraries and tools from the open-source community. We would like to acknowledge and deeply thank the contributors of these projects! ‚ú® üåü üí´ üìù Citation If you find Oumi useful in your research, please consider citing it: üìú License This project is licensed under the Apache License 2.0. See the LICENSE file for details. ^1: Open models are defined as models with fully open weights, training code, and data, and a permissive license. See Open Source Definitions for more information.