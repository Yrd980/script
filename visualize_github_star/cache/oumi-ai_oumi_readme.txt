> !NOTE > Aug 14 Webinar - OpenAI's gpt-oss: Separating the Substance from the Hype. Places limited! !Oumi Logo !Documentationhttps://oumi.ai/docs/en/latest/index.html !Bloghttps://oumi.ai/blog !Twitterhttps://x.com/OumiPBC !Discordhttps://discord.gg/oumi !PyPI versionhttps://badge.fury.io/py/oumi !Licensehttps://opensource.org/licenses/Apache-2.0 !Testshttps://github.com/oumi-ai/oumi/actions/workflows/pretest.yaml !GPU Testshttps://github.com/oumi-ai/oumi/actions/workflows/gputests.yaml !GitHub Repo starshttps://github.com/oumi-ai/oumi/stargazers !Code style: blackhttps://github.com/psf/black !pre-commithttps://github.com/pre-commit/pre-commit !Abouthttps://oumi.ai Everything you need to build state-of-the-art foundation models, end-to-end. <p align="center"> <a href="https://trendshift.io/repositories/12865"> <img alt="GitHub trending" src="https://trendshift.io/api/badge/repositories/12865" /> </a> </p> ğŸ”¥ News - 2025/08 Aug 14 Webinar - OpenAI's gpt-oss: Separating the Substance from the Hype. Places limited! - 2025/08 Oumi v0.3.0 released with model quantization AWQ, an improved LLM-as-a-Judge API, and Adaptive Inference - 2025/07 Recipe for Qwen3 235B - 2025/07 July 24 webinar: "Training a State-of-the-art Agent LLM with Oumi + Lambda" - 2025/06 Oumi v0.2.0 released with support for GRPO fine-tuning, a plethora of new model support, and much more - 2025/06 Announcement of Data Curation for Vision Language Models DCVLR competition at NeurIPS2025 - 2025/06 Recipes for training, inference, and eval with the newly released Falcon-H1 and Falcon-E models - 2025/05 Support and recipes for InternVL3 1B - 2025/04 Added support for training and inference with Llama 4 models: Scout 17B activated, 109B total and Maverick 17B activated, 400B total variants, including full fine-tuning, LoRA, and QLoRA configurations - 2025/04 Recipes for Qwen3 model family - 2025/04 Introducing HallOumi: a State-of-the-Art Claim-Verification Model technical overview - 2025/04 Oumi now supports two new Vision-Language models: Phi4 and Qwen 2.5 ğŸ” About Oumi is a fully open-source platform that streamlines the entire lifecycle of foundation models - from data preparation and training to evaluation and deployment. Whether you're developing on a laptop, launching large scale experiments on a cluster, or deploying models in production, Oumi provides the tools and workflows you need. With Oumi, you can: - ğŸš€ Train and fine-tune models from 10M to 405B parameters using state-of-the-art techniques SFT, LoRA, QLoRA, DPO, and more - ğŸ¤– Work with both text and multimodal models Llama, DeepSeek, Qwen, Phi, and others - ğŸ”„ Synthesize and curate training data with LLM judges - âš¡ï¸ Deploy models efficiently with popular inference engines vLLM, SGLang - ğŸ“Š Evaluate models comprehensively across standard benchmarks - ğŸŒ Run anywhere - from laptops to clusters to clouds AWS, Azure, GCP, Lambda, and more - ğŸ”Œ Integrate with both open models and commercial APIs OpenAI, Anthropic, Vertex AI, Together, Parasail, ... All with one consistent API, production-grade reliability, and all the flexibility you need for research. Learn more at oumi.ai, or jump right in with the quickstart guide. ğŸš€ Getting Started | Notebook | Try in Colab | Goal | |----------|--------------|-------------| | ğŸ¯ Getting Started: A Tour | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - A Tour.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Quick tour of core features: training, evaluation, inference, and job management | | ğŸ”§ Model Finetuning Guide | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Finetuning Tutorial.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | End-to-end guide to LoRA tuning with data prep, training, and evaluation | | ğŸ“š Model Distillation | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Distill a Large Model.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Guide to distilling large models into smaller, efficient ones | | ğŸ“‹ Model Evaluation | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Evaluation with Oumi.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Comprehensive model evaluation using Oumi's evaluation framework | | â˜ï¸ Remote Training | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Running Jobs Remotely.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Launch and monitor training jobs on cloud AWS, Azure, GCP, Lambda, etc. platforms | | ğŸ“ˆ LLM-as-a-Judge | <a target="blank" href="https://colab.research.google.com/github/oumi-ai/oumi/blob/main/notebooks/Oumi - Simple Judge.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | Filter and curate training data with built-in judges | ğŸ”§ Usage Installation Installing oumi in your environment is straightforward: For more advanced installation options, see the installation guide. Oumi CLI You can quickly use the command to train, evaluate, and infer models using one of the existing recipes: For more advanced options, see the training, evaluation, inference, and llm-as-a-judge guides. Running Jobs Remotely You can run jobs remotely on cloud platforms AWS, Azure, GCP, Lambda, etc. using the command: Note: Oumi is in <ins>beta</ins> and under active development. The core features are stable, but some advanced features might change as the platform improves. ğŸ’» Why use Oumi? If you need a comprehensive platform for training, evaluating, or deploying models, Oumi is a great choice. Here are some of the key features that make Oumi stand out: - ğŸ”§ Zero Boilerplate: Get started in minutes with ready-to-use recipes for popular models and workflows. No need to write training loops or data pipelines. - ğŸ¢ Enterprise-Grade: Built and validated by teams training models at scale - ğŸ¯ Research Ready: Perfect for ML research with easily reproducible experiments, and flexible interfaces for customizing each component. - ğŸŒ Broad Model Support: Works with most popular model architectures - from tiny models to the largest ones, text-only to multimodal. - ğŸš€ SOTA Performance: Native support for distributed training techniques FSDP, DDP and optimized inference engines vLLM, SGLang. - ğŸ¤ Community First: 100% open source with an active community. No vendor lock-in, no strings attached. ğŸ“š Examples & Recipes Explore the growing collection of ready-to-use configurations for state-of-the-art models and training workflows: Note: These configurations are not an exhaustive list of what's supported, simply examples to get you started. You can find a more exhaustive list of supported models, and datasets supervised fine-tuning, pre-training, preference tuning, and vision-language finetuning in the oumi documentation. Qwen Family | Model | Example Configurations | |-------|------------------------| | Qwen3 30B A3B | LoRA â€¢ Inference â€¢ Evaluation | | Qwen3 32B | LoRA â€¢ Inference â€¢ Evaluation | | QwQ 32B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference â€¢ Evaluation | | Qwen2.5-VL 3B | SFT â€¢ LoRAâ€¢ Inference vLLM â€¢ Inference | | Qwen2-VL 2B | SFT â€¢ LoRA â€¢ Inference vLLM â€¢ Inference SGLang â€¢ Inference â€¢ Evaluation | ğŸ‹ DeepSeek R1 Family | Model | Example Configurations | |-------|------------------------| | DeepSeek R1 671B | Inference Together AI | | Distilled Llama 8B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference â€¢ Evaluation | | Distilled Llama 70B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference â€¢ Evaluation | | Distilled Qwen 1.5B | FFT â€¢ LoRA â€¢ Inference â€¢ Evaluation | | Distilled Qwen 32B | LoRA â€¢ Inference â€¢ Evaluation | ğŸ¦™ Llama Family | Model | Example Configurations | |-------|------------------------| | Llama 4 Scout Instruct 17B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference vLLM â€¢ Inference â€¢ Inference Together.ai | | Llama 4 Scout 17B | FFT | | Llama 3.1 8B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Pre-training â€¢ Inference vLLM â€¢ Inference â€¢ Evaluation | | Llama 3.1 70B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference â€¢ Evaluation | | Llama 3.1 405B | FFT â€¢ LoRA â€¢ QLoRA | | Llama 3.2 1B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference vLLM â€¢ Inference SGLang â€¢ Inference â€¢ Evaluation | | Llama 3.2 3B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference vLLM â€¢ Inference SGLang â€¢ Inference â€¢ Evaluation | | Llama 3.3 70B | FFT â€¢ LoRA â€¢ QLoRA â€¢ Inference vLLM â€¢ Inference â€¢ Evaluation | | Llama 3.2 Vision 11B | SFT â€¢ Inference vLLM â€¢ Inference SGLang â€¢ Evaluation | ğŸ¦… Falcon family | Model | Example Configurations | |-------|------------------------| | Falcon-H1 | FFT â€¢ Inference â€¢ Evaluation | | Falcon-E BitNet | FFT â€¢ DPO â€¢ Evaluation | ğŸ¨ Vision Models | Model | Example Configurations | |-------|------------------------| | Llama 3.2 Vision 11B | SFT â€¢ LoRA â€¢ Inference vLLM â€¢ Inference SGLang â€¢ Evaluation | | LLaVA 7B | SFT â€¢ Inference vLLM â€¢ Inference | | Phi3 Vision 4.2B | SFT â€¢ LoRA â€¢ Inference vLLM | | Phi4 Vision 5.6B | SFT â€¢ LoRA â€¢ Inference vLLM â€¢ Inference | | Qwen2-VL 2B | SFT â€¢ LoRA â€¢ Inference vLLM â€¢ Inference SGLang â€¢ Inference â€¢ Evaluation | | Qwen2.5-VL 3B | SFT â€¢ LoRAâ€¢ Inference vLLM â€¢ Inference | | SmolVLM-Instruct 2B | SFT â€¢ LoRA | ğŸ” Even more options This section lists all the language models that can be used with Oumi. Thanks to the integration with the ğŸ¤— Transformers library, you can easily use any of these models for training, evaluation, or inference. Models prefixed with a checkmark âœ… have been thoroughly tested and validated by the Oumi community, with ready-to-use recipes available in the configs/recipes directory. <details> <summary>ğŸ“‹ Click to see more supported models</summary> Instruct Models | Model | Size | Paper | HF Hub | License | Open ^1 | Recommended Parameters | |-------|------|-------|---------|----------|------|------------------------| | âœ… SmolLM-Instruct | 135M/360M/1.7B | Blog | Hub | Apache 2.0 | âœ… | | | âœ… DeepSeek R1 Family | 1.5B/8B/32B/70B/671B | Blog | Hub | MIT | âŒ | | | âœ… Llama 3.1 Instruct | 8B/70B/405B | Paper | Hub | License | âŒ | | | âœ… Llama 3.2 Instruct | 1B/3B | Paper | Hub | License | âŒ | | | âœ… Llama 3.3 Instruct | 70B | Paper | Hub | License | âŒ | | | âœ… Phi-3.5-Instruct | 4B/14B | Paper | Hub | License | âŒ | | | Qwen2.5-Instruct | 0.5B-70B | Paper | Hub | License | âŒ | | | OLMo 2 Instruct | 7B | Paper | Hub | Apache 2.0 | âœ… | | | MPT-Instruct | 7B | Blog | Hub | Apache 2.0 | âœ… | | | Command R | 35B/104B | Blog | Hub | License | âŒ | | | Granite-3.1-Instruct | 2B/8B | Paper | Hub | Apache 2.0 | âŒ | | | Gemma 2 Instruct | 2B/9B | Blog | Hub | License | âŒ | | | DBRX-Instruct | 130B MoE | Blog | Hub | Apache 2.0 | âŒ | | | Falcon-Instruct | 7B/40B | Paper | Hub | Apache 2.0 | âŒ | | | âœ… Llama 4 Scout Instruct | 17B Activated 109B Total | Paper | Hub | License | âŒ | | | âœ… Llama 4 Maverick Instruct | 17B Activated 400B Total | Paper | Hub | License | âŒ | | Vision-Language Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | âœ… Llama 3.2 Vision | 11B | Paper | Hub | License | âŒ | | | âœ… LLaVA-1.5 | 7B | Paper | Hub | License | âŒ | | | âœ… Phi-3 Vision | 4.2B | Paper | Hub | License | âŒ | | | âœ… BLIP-2 | 3.6B | Paper | Hub | MIT | âŒ | | | âœ… Qwen2-VL | 2B | Blog | Hub | License | âŒ | | | âœ… SmolVLM-Instruct | 2B | Blog | Hub | Apache 2.0 | âœ… | | Base Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | âœ… SmolLM2 | 135M/360M/1.7B | Blog | Hub | Apache 2.0 | âœ… | | | âœ… Llama 3.2 | 1B/3B | Paper | Hub | License | âŒ | | | âœ… Llama 3.1 | 8B/70B/405B | Paper | Hub | License | âŒ | | | âœ… GPT-2 | 124M-1.5B | Paper | Hub | MIT | âœ… | | | DeepSeek V2 | 7B/13B | Blog | Hub | License | âŒ | | | Gemma2 | 2B/9B | Blog | Hub | License | âŒ | | | GPT-J | 6B | Blog | Hub | Apache 2.0 | âœ… | | | GPT-NeoX | 20B | Paper | Hub | Apache 2.0 | âœ… | | | Mistral | 7B | Paper | Hub | Apache 2.0 | âŒ | | | Mixtral | 8x7B/8x22B | Blog | Hub | Apache 2.0 | âŒ | | | MPT | 7B | Blog | Hub | Apache 2.0 | âœ… | | | OLMo | 1B/7B | Paper | Hub | Apache 2.0 | âœ… | | | âœ… Llama 4 Scout | 17B Activated 109B Total | Paper | Hub | License | âŒ | | Reasoning Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | Qwen QwQ | 32B | Blog | Hub | License | âœ… | | Code Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | âœ… Qwen2.5 Coder | 0.5B-32B | Blog | Hub | License | âŒ | | | DeepSeek Coder | 1.3B-33B | Paper | Hub | License | âŒ | | | StarCoder 2 | 3B/7B/15B | Paper | Hub | License | âœ… | | Math Models | Model | Size | Paper | HF Hub | License | Open | Recommended Parameters | |-------|------|-------|---------|----------|------|---------------------| | DeepSeek Math | 7B | Paper | Hub | License | âŒ | | </details> ğŸ“– Documentation To learn more about all the platform's capabilities, see the Oumi documentation. ğŸ¤ Join the Community! Oumi is a community-first effort. Whether you are a developer, a researcher, or a non-technical user, all contributions are very welcome! - To contribute to the repository, please check the https://github.com/oumi-ai/oumi/blob/main/CONTRIBUTING.md for guidance on how to contribute to send your first Pull Request. - Make sure to join our Discord community to get help, share your experiences, and contribute to the project! - If you are interested in joining one of the community's open-science efforts, check out our open collaboration page. ğŸ™ Acknowledgements Oumi makes use of several libraries and tools from the open-source community. We would like to acknowledge and deeply thank the contributors of these projects! âœ¨ ğŸŒŸ ğŸ’« ğŸ“ Citation If you find Oumi useful in your research, please consider citing it: ğŸ“œ License This project is licensed under the Apache License 2.0. See the LICENSE file for details. ^1: Open models are defined as models with fully open weights, training code, and data, and a permissive license. See Open Source Definitions for more information.