One Small Step -------------- by @karminski-牙医 !one-small-step 这是一个简单的技术科普教程项目, 主要聚焦于解释一些有趣的, 前沿的技术概念和原理. 每篇文章都力求在 5 分钟内阅读完成. !Metrics 目前更新速度👆, 力求每周不低于3篇 文章列表 人工智能相关 - 什么是 GGUF - 介绍 GGUF 文件格式及其在大语言模型部署中的应用 - 什么是推测性解码 - 解释推测性解码技术如何提升大语言模型的推理性能 - 什么是 Pythonic 函数调用 - 为什么 Pythonic 函数调用 比 function call 效果好? - 如何本地运行 GGUF 格式的 LLM 模型 - 如何本地运行 GGUF 格式的 LLM 模型? - 什么是 LLM 蒸馏技术 - 什么是 LLM 蒸馏技术? - 什么是 Transformer - 什么是 Transformer? - 如何优化 Transformer - Transformer 的优化方案都有哪些? - 什么是大语言模型量化 - 什么是大语言模型量化? 每个量化精度都代表什么? - 什么是 Flash Attention - 什么是 Flash Attention? 为什么能将大语言模型推理速度提升3倍? - 什么是 Multi-Head Attention - 什么是 Multi-Head Attention? Attention Is All You Need 论文精读 - 什么是 Multi-Query Attention - 什么是 Multi-Query Attention? - 什么是 Grouped Query Attention - 什么是 Grouped Query Attention? - 什么是 LLM 微调技术 - 什么是 LLM 微调技术? - 什么是 RAG 技术 - 什么是 RAG 技术? - 什么是 Safetensors - 什么是 Safetensors? - 什么是 ONNX - 什么是 ONNX? - 大模型微调最佳实践指南 - 大模型微调最佳实践指南 - 什么是 MoE 模型 - 什么是 MoE 模型? - LLM 中的 Token 是如何计算的 - LLM 中的 Token 是如何计算的? - 什么是 AI Agent - 什么是 AI Agent? - 什么是 LoRA - 什么是 LoRA? 为什么用 LoRA 微调大模型更高效? - 什么是向量嵌入 - 什么是向量嵌入? - 什么是向量数据库 - 什么是向量数据库? - 什么是 AI 幻觉 - 什么是 AI 幻觉? - 什么是模态编码 - 什么是模态编码? - 什么是表示空间 - 什么是表示空间? - 什么是多模态模型 - 什么是多模态模型? - 什么是 LLM 的困惑度 - 什么是大模型的困惑度? 为什么量化版本要用困惑度来评价量化质量? - 如何避免 KVCache 失效 - 当心动态内容, 会导致 KVCache 失效 - 什么是 Sliding Window Attention - 什么是滑动窗口注意力 - 什么时候应该微调, 什么时候不应该微调? - 微调和RAG还如何选择? - Qwen3 扩展到 1M 上下文是如何做到的? - 什么是 DCA? 数学相关 - 什么是矩阵的秩？什么是低秩矩阵？ - 什么是矩阵的秩？什么是低秩矩阵？ - 什么是拟合与过拟合 - 什么是拟合与过拟合? 系统相关 - Windows 任务管理器内存标签说明 - 详解 Windows 任务管理器中各个内存指标的含义 - RAMMap 使用解析 - 详解 RAMMap 的使用方法 硬件相关 - 什么是 PCIe Retimer - 详解 PCIe Retimer 的原理和应用 - 为什么有的 NVMe SSD 有 DRAM, 有的没有? - 为什么有的 NVMe SSD 有 DRAM, 有的没有? - CLX 会是大语言模型的内存解决方案吗? - 什么? PCIe 上能插内存了? - 什么是 1DPC - 什么是 1DPC? 为什么内存条要插在远端插槽? - 什么是 L1 缓存 - 什么是 L1 缓存? 它的工作原理是什么? 贡献 由于个人能力有限, 难免会有错误, 欢迎大家指正, 任何形式的贡献或者讨论都十分欢迎, 可以提交 issue 或者直接 PR. Star History !Star History Charthttps://star-history.com/karminski/one-small-step&Date 许可 本项目采用 MIT 许可证. 详见 LICENSE 文件.