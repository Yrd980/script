Supported functions |Speech recognition| Speech synthesistts-url | Source separationss-url | |------------------|------------------|-------------------| | ✔️ | ✔️ | ✔️ | |Speaker identification| Speaker diarizationsd-url | Speaker verification | |----------------------|-------------------- |------------------------| | ✔️ | ✔️ | ✔️ | | Spoken Language identificationslid-url | Audio taggingat-url | Voice activity detectionvad-url | |--------------------------------|---------------|--------------------------| | ✔️ | ✔️ | ✔️ | | Keyword spottingkws-url | Add punctuationpunct-url | Speech enhancementse-url | |------------------|-----------------|--------------------| | ✔️ | ✔️ | ✔️ | Supported platforms |Architecture| Android | iOS | Windows | macOS | linux | HarmonyOS | |------------|---------|---------|------------|-------|-------|-----------| | x64 | ✔️ | | ✔️ | ✔️ | ✔️ | ✔️ | | x86 | ✔️ | | ✔️ | | | | | arm64 | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | | arm32 | ✔️ | | | | ✔️ | ✔️ | | riscv64 | | | | | ✔️ | | Supported programming languages | 1. C++ | 2. C | 3. Python | 4. JavaScript | |--------|-------|-----------|---------------| | ✔️ | ✔️ | ✔️ | ✔️ | |5. Java | 6. C | 7. Kotlin | 8. Swift | |--------|-------|-----------|----------| | ✔️ | ✔️ | ✔️ | ✔️ | | 9. Go | 10. Dart | 11. Rust | 12. Pascal | |-------|----------|----------|------------| | ✔️ | ✔️ | ✔️ | ✔️ | For Rust support, please see sherpa-rssherpa-rs It also supports WebAssembly. Introduction This repository supports running the following functions locally - Speech-to-text i.e., ASR; both streaming and non-streaming are supported - Text-to-speech i.e., TTS - Speaker diarization - Speaker identification - Speaker verification - Spoken language identification - Audio tagging - VAD e.g., silero-vadsilero-vad - Speech enhancement e.g., gtcrngtcrn - Keyword spotting - Source separation e.g., spleeterspleeter, UVRUVR on the following platforms and operating systems: - x86, - Java, Kotlin, JavaScript - Swift, Rust - Dart, Object Pascal Links for Huggingface Spaces <details> <summary>You can visit the following Huggingface spaces to try sherpa-onnx without installing anything. All you need is a browser.</summary> | Description | URL | 中国镜像 | |-------------------------------------------------------|-----------------------------------------|----------------------------------------| | Speaker diarization | Click mehf-space-speaker-diarization| 镜像hf-space-speaker-diarization-cn| | Speech recognition | Click mehf-space-asr | 镜像hf-space-asr-cn | | Speech recognition with WhisperWhisper | Click mehf-space-asr-whisper | 镜像hf-space-asr-whisper-cn | | Speech synthesis | Click mehf-space-tts | 镜像hf-space-tts-cn | | Generate subtitles | Click mehf-space-subtitle | 镜像hf-space-subtitle-cn | | Audio tagging | Click mehf-space-audio-tagging | 镜像hf-space-audio-tagging-cn | | Source separation | Click mehf-space-source-separation | 镜像hf-space-source-separation-cn | | Spoken language identification with WhisperWhisper| Click mehf-space-slid-whisper | 镜像hf-space-slid-whisper-cn | We also have spaces built using WebAssembly. They are listed below: | Description | Huggingface space| ModelScope space| |------------------------------------------------------------------------------------------|------------------|-----------------| |Voice activity detection with silero-vadsilero-vad | Click mewasm-hf-vad|地址wasm-ms-vad| |Real-time speech recognition Chinese + English with Zipformer | Click mewasm-hf-streaming-asr-zh-en-zipformer|地址wasm-hf-streaming-asr-zh-en-zipformer| |Real-time speech recognition Chinese + English with Paraformer |Click mewasm-hf-streaming-asr-zh-en-paraformer| 地址wasm-ms-streaming-asr-zh-en-paraformer| |Real-time speech recognition Chinese + English + Cantonese with Paraformer-largeParaformer-large|Click mewasm-hf-streaming-asr-zh-en-yue-paraformer| 地址wasm-ms-streaming-asr-zh-en-yue-paraformer| |Real-time speech recognition English |Click mewasm-hf-streaming-asr-en-zipformer |地址wasm-ms-streaming-asr-en-zipformer| |VAD + speech recognition Chinese with Zipformer CTC|Click mewasm-hf-vad-asr-zh-zipformer-ctc-07-03| 地址wasm-ms-vad-asr-zh-zipformer-ctc-07-03| |VAD + speech recognition Chinese + English + Korean + Japanese + Cantonese with SenseVoiceSenseVoice|Click mewasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice| 地址wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice| |VAD + speech recognition English with WhisperWhisper tiny.en|Click mewasm-hf-vad-asr-en-whisper-tiny-en| 地址wasm-ms-vad-asr-en-whisper-tiny-en| |VAD + speech recognition English with Moonshine tinyMoonshine tiny|Click mewasm-hf-vad-asr-en-moonshine-tiny-en| 地址wasm-ms-vad-asr-en-moonshine-tiny-en| |VAD + speech recognition English with Zipformer trained with GigaSpeechGigaSpeech |Click mewasm-hf-vad-asr-en-zipformer-gigaspeech| 地址wasm-ms-vad-asr-en-zipformer-gigaspeech| |VAD + speech recognition Chinese with Zipformer trained with WenetSpeechWenetSpeech |Click mewasm-hf-vad-asr-zh-zipformer-wenetspeech| 地址wasm-ms-vad-asr-zh-zipformer-wenetspeech| |VAD + speech recognition Japanese with Zipformer trained with ReazonSpeechReazonSpeech|Click mewasm-hf-vad-asr-ja-zipformer-reazonspeech| 地址wasm-ms-vad-asr-ja-zipformer-reazonspeech| |VAD + speech recognition Thai with Zipformer trained with GigaSpeech2GigaSpeech2 |Click mewasm-hf-vad-asr-th-zipformer-gigaspeech2| 地址wasm-ms-vad-asr-th-zipformer-gigaspeech2| |VAD + speech recognition Chinese 多种方言 with a TeleSpeech-ASRTeleSpeech-ASR CTC model|Click mewasm-hf-vad-asr-zh-telespeech| 地址wasm-ms-vad-asr-zh-telespeech| |VAD + speech recognition English + Chinese, 及多种中文方言 with Paraformer-large |Click mewasm-hf-vad-asr-zh-en-paraformer-large| 地址wasm-ms-vad-asr-zh-en-paraformer-large| |VAD + speech recognition English + Chinese, 及多种中文方言 with Paraformer-small |Click mewasm-hf-vad-asr-zh-en-paraformer-small| 地址wasm-ms-vad-asr-zh-en-paraformer-small| |VAD + speech recognition 多语种及多种中文方言 with DolphinDolphin-base |Click mewasm-hf-vad-asr-multi-lang-dolphin-base| 地址wasm-ms-vad-asr-multi-lang-dolphin-base| |Speech synthesis English |Click mewasm-hf-tts-piper-en| 地址wasm-ms-tts-piper-en| |Speech synthesis German |Click mewasm-hf-tts-piper-de| 地址wasm-ms-tts-piper-de| |Speaker diarization |Click mewasm-hf-speaker-diarization|地址wasm-ms-speaker-diarization| </details> Links for pre-built Android APKs <details> <summary>You can find pre-built Android APKs for this repository in the following table</summary> | Description | URL | 中国用户 | |----------------------------------------|------------------------------------|-----------------------------------| | Speaker diarization | Addressapk-speaker-diarization | 点此apk-speaker-diarization-cn| | Streaming speech recognition | Addressapk-streaming-asr | 点此apk-streaming-asr-cn | | Simulated-streaming speech recognition | Addressapk-simula-streaming-asr| 点此apk-simula-streaming-asr-cn| | Text-to-speech | Addressapk-tts | 点此apk-tts-cn | | Voice activity detection VAD | Addressapk-vad | 点此apk-vad-cn | | VAD + non-streaming speech recognition | Addressapk-vad-asr | 点此apk-vad-asr-cn | | Two-pass speech recognition | Addressapk-2pass | 点此apk-2pass-cn | | Audio tagging | Addressapk-at | 点此apk-at-cn | | Audio tagging WearOS | Addressapk-at-wearos | 点此apk-at-wearos-cn | | Speaker identification | Addressapk-sid | 点此apk-sid-cn | | Spoken language identification | Addressapk-slid | 点此apk-slid-cn | | Keyword spotting | Addressapk-kws | 点此apk-kws-cn | </details> Links for pre-built Flutter APPs <details> Real-time speech recognition | Description | URL | 中国用户 | |--------------------------------|-------------------------------------|-------------------------------------| | Streaming speech recognition | Addressapk-flutter-streaming-asr| 点此apk-flutter-streaming-asr-cn| Text-to-speech | Description | URL | 中国用户 | |------------------------------------------|------------------------------------|------------------------------------| | Android arm64-v8a, armeabi-v7a, x8664 | Addressflutter-tts-android | 点此flutter-tts-android-cn | | Linux x64 | Addressflutter-tts-linux | 点此flutter-tts-linux-cn | | macOS x64 | Addressflutter-tts-macos-x64 | 点此flutter-tts-macos-arm64-cn | | macOS arm64 | Addressflutter-tts-macos-arm64 | 点此flutter-tts-macos-x64-cn | | Windows x64 | Addressflutter-tts-win-x64 | 点此flutter-tts-win-x64-cn | > Note: You need to build from source for iOS. </details> Links for pre-built Lazarus APPs <details> Generating subtitles | Description | URL | 中国用户 | |--------------------------------|----------------------------|----------------------------| | Generate subtitles 生成字幕 | Addresslazarus-subtitle| 点此lazarus-subtitle-cn| </details> Links for pre-trained models <details> | Description | URL | |---------------------------------------------|---------------------------------------------------------------------------------------| | Speech recognition speech to text, ASR | Addressasr-models | | Text-to-speech TTS | Addresstts-models | | VAD | Addressvad-models | | Keyword spotting | Addresskws-models | | Audio tagging | Addressat-models | | Speaker identification Speaker ID | Addresssid-models | | Spoken language identification Language ID| See multi-lingual WhisperWhisper ASR models from Speech recognitionasr-models| | Punctuation | Addresspunct-models | | Speaker segmentation | Addressspeaker-segmentation-models | | Speech enhancement | Addressspeech-enhancement-models | | Source separation | Addresssource-separation-models | </details> Some pre-trained ASR models Streaming <details> Please see - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/online-transducer/index.html> - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/online-paraformer/index.html> - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/online-ctc/index.html> for more models. The following table lists only SOME of them. |Name | Supported Languages| Description| |-----|-----|----| |sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20| Chinese, English| See also| |sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16| Chinese, English| See also| |sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23|Chinese| Suitable for Cortex A7 CPU. See also| |sherpa-onnx-streaming-zipformer-en-20M-2023-02-17sherpa-onnx-streaming-zipformer-en-20M-2023-02-17|English|Suitable for Cortex A7 CPU. See also| |sherpa-onnx-streaming-zipformer-korean-2024-06-16sherpa-onnx-streaming-zipformer-korean-2024-06-16|Korean| See also| |sherpa-onnx-streaming-zipformer-fr-2023-04-14sherpa-onnx-streaming-zipformer-fr-2023-04-14|French| See also| </details> Some pre-trained ASR models Non-Streaming <details> Please see - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/offline-transducer/index.html> - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/offline-paraformer/index.html> - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/offline-ctc/index.html> - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/telespeech/index.html> - <https://k2-fsa.github.io/sherpa/onnx/pretrainedmodels/whisper/index.html> for more models. The following table lists only SOME of them. |Name | Supported Languages| Description| |-----|-----|----| |sherpa-onnx-nemo-parakeet-tdt-0.6b-v2-int8| English | It is converted from <https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2>| |Whisper tiny.en|English| See also| |Moonshine tinyMoonshine tiny|English|See also| |sherpa-onnx-zipformer-ctc-zh-int8-2025-07-03|Chinese| A Zipformer CTC model| |sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17|Chinese, Cantonese, English, Korean, Japanese| 支持多种中文方言. See also| |sherpa-onnx-paraformer-zh-2024-03-09sherpa-onnx-paraformer-zh-2024-03-09|Chinese, English| 也支持多种中文方言. See also| |sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01|Japanese|See also| |sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24|Russian|See also| |sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24|Russian| See also| |sherpa-onnx-zipformer-ru-2024-09-18sherpa-onnx-zipformer-ru-2024-09-18|Russian|See also| |sherpa-onnx-zipformer-korean-2024-06-24sherpa-onnx-zipformer-korean-2024-06-24|Korean|See also| |sherpa-onnx-zipformer-thai-2024-06-20sherpa-onnx-zipformer-thai-2024-06-20|Thai| See also| |sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04|Chinese| 支持多种方言. See also| </details> Useful links - Documentation: https://k2-fsa.github.io/sherpa/onnx/ - Bilibili 演示视频: https://search.bilibili.com/all?keyword=%E6%96%B0%E4%B8%80%E4%BB%A3Kaldi How to reach us Please see https://k2-fsa.github.io/sherpa/social-groups.html for 新一代 Kaldi 微信交流群 and QQ 交流群. Projects using sherpa-onnx BreezeApp from MediaTek Research > BreezeAPP is a mobile AI application developed for both Android and iOS platforms. > Users can download it directly from the App Store and enjoy a variety of features > offline, including speech-to-text, text-to-speech, text-based chatbot interactions, > and image question-answering - Download APK for BreezeAPP - APK 中国镜像 | 1 | 2 | 3 | |---|---|---| |!https://github.com/user-attachments/assets/1cdbc057-b893-4de6-9e9c-f1d7dfd1d992|!https://github.com/user-attachments/assets/d77cd98e-b057-442f-860d-d5befd5c769b|!https://github.com/user-attachments/assets/57e546bf-3d39-45b9-b392-b48ca4fb3c58| Open-LLM-VTuber Talk to any LLM with hands-free voice interaction, voice interruption, and Live2D taking face running locally across platforms See also <https://github.com/t41372/Open-LLM-VTuber/pull/50> voiceapi <details> <summary>Streaming ASR and TTS based on FastAPI</summary> It shows how to use the ASR and TTS Python APIs with FastAPI. </details> 腾讯会议摸鱼工具 TMSpeech Uses streaming ASR in C with graphical user interface. Video demo in Chinese: 【开源】Windows实时字幕软件（网课/开会必备） lol互动助手 It uses the JavaScript API of sherpa-onnx along with Electron Video demo in Chinese: 爆了！炫神教你开打字挂！真正影响胜率的英雄联盟工具！英雄联盟的最后一块拼图！和游戏中的每个人无障碍沟通！ Sherpa-ONNX 语音识别服务器 A server based on nodejs providing Restful API for speech recognition. QSmartAssistant 一个模块化，全过程可离线，低占用率的对话机器人/智能音箱 It uses QT. Both ASR and TTS are used. Flutter-EasySpeechRecognition It extends ./flutter-examples/streamingasr by downloading models inside the app to reduce the size of the app. Note: Team B Sherpa AI backendhttps://github.com/umgc/spring2025/pull/82 also uses sherpa-onnx in a Flutter APP. sherpa-onnx-unity sherpa-onnx in Unity. See also 1695, 1892, and 1859 xiaozhi-esp32-server 本项目为xiaozhi-esp32提供后端服务，帮助您快速搭建ESP32设备控制服务器 Backend service for xiaozhi-esp32, helps you quickly build an ESP32 device control server. See also - ASR新增轻量级sherpa-onnx-asr - feat: ASR增加sherpa-onnx模型 KaithemAutomation Pure Python, GUI-focused home automation/consumer grade SCADA. It uses TTS from sherpa-onnx. See also ✨ Speak command that uses the new globally configured TTS model. Open-XiaoAI KWS Enable custom wake word for XiaoAi Speakers. 让小爱音箱支持自定义唤醒词。 Video demo in Chinese: 小爱同学启动～˶╹ꇴ╹˶！ C++ WebSocket ASR Server It provides a WebSocket server based on C++ for ASR using sherpa-onnx. Go WebSocket Server It provides a WebSocket server based on the Go programming language for sherpa-onnx. Making robot Paimon, Ep10 "The AI Part 1" It is a YouTube video, showing how the author tried to use AI so he can have a conversation with Paimon. It uses sherpa-onnx for speech-to-text and text-to-speech. |1| |---| |!https://github.com/user-attachments/assets/f6eea2d5-1807-42cb-9160-be8da2971e1f| sherpa-rs: https://github.com/thewh1teagle/sherpa-rs silero-vad: https://github.com/snakers4/silero-vad Raspberry Pi: https://www.raspberrypi.com/ RV1126: https://www.rock-chips.com/uploads/pdf/2022.8.26/191/RV1126%20Brief%20Datasheet.pdf LicheePi4A: https://sipeed.com/licheepi4a VisionFive 2: https://www.starfivetech.com/en/site/boards 旭日X3派: https://developer.horizon.ai/api/v1/fileData/documentspi/index.html 爱芯派: https://wiki.sipeed.com/hardware/zh/maixIII/ax-pi/axpi.html hf-space-speaker-diarization: https://huggingface.co/spaces/k2-fsa/speaker-diarization hf-space-speaker-diarization-cn: https://hf.qhduan.com/spaces/k2-fsa/speaker-diarization hf-space-asr: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition hf-space-asr-cn: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition Whisper: https://github.com/openai/whisper hf-space-asr-whisper: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition-with-whisper hf-space-asr-whisper-cn: https://hf.qhduan.com/spaces/k2-fsa/automatic-speech-recognition-with-whisper hf-space-tts: https://huggingface.co/spaces/k2-fsa/text-to-speech hf-space-tts-cn: https://hf.qhduan.com/spaces/k2-fsa/text-to-speech hf-space-subtitle: https://huggingface.co/spaces/k2-fsa/generate-subtitles-for-videos hf-space-subtitle-cn: https://hf.qhduan.com/spaces/k2-fsa/generate-subtitles-for-videos hf-space-audio-tagging: https://huggingface.co/spaces/k2-fsa/audio-tagging hf-space-audio-tagging-cn: https://hf.qhduan.com/spaces/k2-fsa/audio-tagging hf-space-source-separation: https://huggingface.co/spaces/k2-fsa/source-separation hf-space-source-separation-cn: https://hf.qhduan.com/spaces/k2-fsa/source-separation hf-space-slid-whisper: https://huggingface.co/spaces/k2-fsa/spoken-language-identification hf-space-slid-whisper-cn: https://hf.qhduan.com/spaces/k2-fsa/spoken-language-identification wasm-hf-vad: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-sherpa-onnx wasm-ms-vad: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-sherpa-onnx wasm-hf-streaming-asr-zh-en-zipformer: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en wasm-ms-streaming-asr-zh-en-zipformer: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en wasm-hf-streaming-asr-zh-en-paraformer: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer wasm-ms-streaming-asr-zh-en-paraformer: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer Paraformer-large: https://www.modelscope.cn/models/damo/speechparaformer-largeasrnat-zh-cn-16k-common-vocab8404-pytorch/summary wasm-hf-streaming-asr-zh-en-yue-paraformer: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer wasm-ms-streaming-asr-zh-en-yue-paraformer: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer wasm-hf-streaming-asr-en-zipformer: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-en wasm-ms-streaming-asr-en-zipformer: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-en SenseVoice: https://github.com/FunAudioLLM/SenseVoice wasm-hf-vad-asr-zh-zipformer-ctc-07-03: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc wasm-ms-vad-asr-zh-zipformer-ctc-07-03: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-ctc/summary wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-ja-ko-cantonese-sense-voice wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-en-jp-ko-cantonese-sense-voice wasm-hf-vad-asr-en-whisper-tiny-en: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny wasm-ms-vad-asr-en-whisper-tiny-en: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny wasm-hf-vad-asr-en-moonshine-tiny-en: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny wasm-ms-vad-asr-en-moonshine-tiny-en: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny wasm-hf-vad-asr-en-zipformer-gigaspeech: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech wasm-ms-vad-asr-en-zipformer-gigaspeech: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech wasm-hf-vad-asr-zh-zipformer-wenetspeech: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech wasm-ms-vad-asr-zh-zipformer-wenetspeech: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech reazonspeech: https://research.reazon.jp/static/reazonspeechnlp2023.pdf wasm-hf-vad-asr-ja-zipformer-reazonspeech: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-ja-zipformer wasm-ms-vad-asr-ja-zipformer-reazonspeech: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-ja-zipformer gigaspeech2: https://github.com/speechcolab/gigaspeech2 wasm-hf-vad-asr-th-zipformer-gigaspeech2: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-th-zipformer wasm-ms-vad-asr-th-zipformer-gigaspeech2: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-th-zipformer telespeech-asr: https://github.com/tele-ai/telespeech-asr wasm-hf-vad-asr-zh-telespeech: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech wasm-ms-vad-asr-zh-telespeech: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech wasm-hf-vad-asr-zh-en-paraformer-large: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer wasm-ms-vad-asr-zh-en-paraformer-large: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer wasm-hf-vad-asr-zh-en-paraformer-small: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small wasm-ms-vad-asr-zh-en-paraformer-small: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small dolphin: https://github.com/dataoceanai/dolphin wasm-ms-vad-asr-multi-lang-dolphin-base: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc wasm-hf-vad-asr-multi-lang-dolphin-base: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-multi-lang-dophin-ctc wasm-hf-tts-piper-en: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-en wasm-ms-tts-piper-en: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-en wasm-hf-tts-piper-de: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-de wasm-ms-tts-piper-de: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-de wasm-hf-speaker-diarization: https://huggingface.co/spaces/k2-fsa/web-assembly-speaker-diarization-sherpa-onnx wasm-ms-speaker-diarization: https://www.modelscope.cn/studios/csukuangfj/web-assembly-speaker-diarization-sherpa-onnx apk-speaker-diarization: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk.html apk-speaker-diarization-cn: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk-cn.html apk-streaming-asr: https://k2-fsa.github.io/sherpa/onnx/android/apk.html apk-streaming-asr-cn: https://k2-fsa.github.io/sherpa/onnx/android/apk-cn.html apk-simula-streaming-asr: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr.html apk-simula-streaming-asr-cn: https://k2-fsa.github.io/sherpa/onnx/android/apk-simulate-streaming-asr-cn.html apk-tts: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine.html apk-tts-cn: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine-cn.html apk-vad: https://k2-fsa.github.io/sherpa/onnx/vad/apk.html apk-vad-cn: https://k2-fsa.github.io/sherpa/onnx/vad/apk-cn.html apk-vad-asr: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr.html apk-vad-asr-cn: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr-cn.html apk-2pass: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass.html apk-2pass-cn: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass-cn.html apk-at: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk.html apk-at-cn: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-cn.html apk-at-wearos: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos.html apk-at-wearos-cn: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos-cn.html apk-sid: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk.html apk-sid-cn: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk-cn.html apk-slid: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk.html apk-slid-cn: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk-cn.html apk-kws: https://k2-fsa.github.io/sherpa/onnx/kws/apk.html apk-kws-cn: https://k2-fsa.github.io/sherpa/onnx/kws/apk-cn.html apk-flutter-streaming-asr: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app.html apk-flutter-streaming-asr-cn: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app-cn.html flutter-tts-android: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android.html flutter-tts-android-cn: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android-cn.html flutter-tts-linux: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux.html flutter-tts-linux-cn: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux-cn.html flutter-tts-macos-x64: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64.html flutter-tts-macos-arm64-cn: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64-cn.html flutter-tts-macos-arm64: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64.html flutter-tts-macos-x64-cn: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64-cn.html flutter-tts-win-x64: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win.html flutter-tts-win-x64-cn: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win-cn.html lazarus-subtitle: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles.html lazarus-subtitle-cn: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles-cn.html asr-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models tts-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models vad-models: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silerovad.onnx kws-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/kws-models at-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/audio-tagging-models sid-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models slid-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models punct-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/punctuation-models speaker-segmentation-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-segmentation-models GigaSpeech: https://github.com/SpeechColab/GigaSpeech WenetSpeech: https://github.com/wenet-e2e/WenetSpeech sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20.tar.bz2 sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16.tar.bz2 sherpa-onnx-streaming-zipformer-korean-2024-06-16: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-korean-2024-06-16.tar.bz2 sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23.tar.bz2 sherpa-onnx-streaming-zipformer-en-20M-2023-02-17: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-en-20M-2023-02-17.tar.bz2 sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2 sherpa-onnx-zipformer-ru-2024-09-18: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2 sherpa-onnx-zipformer-korean-2024-06-24: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2 sherpa-onnx-zipformer-thai-2024-06-20: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2 sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24.tar.bz2 sherpa-onnx-paraformer-zh-2024-03-09: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-paraformer-zh-2024-03-09.tar.bz2 sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24.tar.bz2 sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04.tar.bz2 sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2 sherpa-onnx-streaming-zipformer-fr-2023-04-14: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-fr-2023-04-14.tar.bz2 Moonshine tiny: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-moonshine-tiny-en-int8.tar.bz2 NVIDIA Jetson Orin NX: https://developer.download.nvidia.com/assets/embedded/secure/jetson/orinnx/docs/JetsonOrinNXDS-10712-001v0.5.pdf?RCPGu9Q6OVAOv7a7vgtwc9-BLScXRIWq6cSLuditMALECJdOj27DgnqAPGVnT2VpiNpQan9SyFy-9zRykR58CokzbXwjSA7Gj819e91AXPrWkGZR3oS1VLxiDEpJaY0lr7UT-N4GnXtb8NlUkP4GkCkkFFQivGPrAucCUywL481GHWpPp7ziHU1Wg==&t=eyJscyI6ImdzZW8iLCJsc2QiOiJodHRwczovL3d3dy5nb29nbGUuY29tLmhrLyJ9 NVIDIA Jetson Nano B01: https://www.seeedstudio.com/blog/2020/01/16/new-revision-of-jetson-nano-dev-kit-now-supports-new-jetson-nano-module/ speech-enhancement-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speech-enhancement-models source-separation-models: https://github.com/k2-fsa/sherpa-onnx/releases/tag/source-separation-models RK3588: https://www.rock-chips.com/uploads/pdf/2022.8.26/192/RK3588%20Brief%20Datasheet.pdf spleeter: https://github.com/deezer/spleeter UVR: https://github.com/Anjok07/ultimatevocalremovergui gtcrn: https://github.com/Xiaobin-Rong/gtcrn tts-url: https://k2-fsa.github.io/sherpa/onnx/tts/all-in-one.html ss-url: https://k2-fsa.github.io/sherpa/onnx/source-separation/index.html sd-url: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/index.html slid-url: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/index.html at-url: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/index.html vad-url: https://k2-fsa.github.io/sherpa/onnx/vad/index.html kws-url: https://k2-fsa.github.io/sherpa/onnx/kws/index.html punct-url: https://k2-fsa.github.io/sherpa/onnx/punctuation/index.html se-url: https://k2-fsa.github.io/sherpa/onnx/speech-enhancment/index.html