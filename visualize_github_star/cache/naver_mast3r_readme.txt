!banner Official implementation of Project page, MASt3R arxiv, DUSt3R arxiv !Example of matching results obtained from MASt3R !High level overview of MASt3R's architecture Table of Contents - Table of Contents - License - Get Started - Installation - Checkpoints - MASt3R Model - Retrieval Model - Dune Model - MASt3R-SfM - Interactive demo - Interactive demo with docker - Usage - Usage MASt3R - Usage DUNE+MASt3R - Training - Datasets - Demo - Our Hyperparameters - Visual Localization - Dataset preparation - Example Commands License The code is distributed under the CC BY-NC-SA 4.0 License. See LICENSE for more information. Get Started Installation 1. Clone MASt3R. 2. Create the environment, here we show an example using conda. 3. compile and install ASMK 4. Optional, compile the cuda kernels for RoPE as in CroCo v2. Checkpoints MASt3R Model You can obtain the model checkpoints by two ways: 1 You can use our huggingfacehub integration: the models will be downloaded automatically. 2 Otherwise, download it from our server: | Modelname | Training resolutions | Head | Encoder | Decoder | |-------------|----------------------|------|---------|---------| | https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3RViTLargeBaseDecoder512catmlpdptmetric.pth | 512x384, 512x336, 512x288, 512x256, 512x160 | CatMLP+DPT | ViT-L | ViT-B | You can check the hyperparameters we used to train these models in the section: Our Hyperparameters Make sure to check license of the datasets we used. To download : Make sure to agree to the license of all the training datasets we used, in addition to CC-BY-NC-SA 4.0. The mapfree dataset license in particular is very restrictive. For more information, check CHECKPOINTSNOTICE. Retrieval Model This retrieval model is for only. You need to download both the and files, and put them in the same directory. https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3RViTLargeBaseDecoder512catmlpdptmetricretrievaltrainingfree.pth https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3RViTLargeBaseDecoder512catmlpdptmetricretrievalcodebook.pkl Dune Model We added partial support of the Dune encoder. Check the associated Dune License. You can find the MASt3R decoder that goes with it here: https://download.europe.naverlabs.com/dune/dunemast3rcvpr25vitbase.pth https://download.europe.naverlabs.com/dune/dunemast3rcvpr25vitsmall.pth This model have limited compatility with the rest of the codebase, but we wanted to include it as it achieves impressive results on the Map-free Visual Relocalization benchmark. Make sure to check the Usage DUNE+MASt3R section if you are interested. MASt3R-SfM A few words about the addition of MASt3R-SfM to this repository. MASt3R-SfM refers to the makepairs retrieval + sparseglobalalignment that you can find here: demo.pyL142. In this repository, you will also find and . These two scripts are unrelated to MASt3R-SfM. They are "toys" that attempt to use mast3r matches to do standard Sfm reconstructions with colmap/glomap. As such, they were not extensively tested, and may fail on edge cases. Interactive demo We made one huggingface space running the new sparse global alignment in a simplified demo for small scenes: naver/MASt3R There are two demos available to run locally: Interactive demo with docker TODO update with asmk/retrieval model To run MASt3R using Docker, including with NVIDIA CUDA support, follow these instructions: 1. Install Docker: If not already installed, download and install and from the Docker website. 2. Install NVIDIA Docker Toolkit: For GPU support, install the NVIDIA Docker toolkit from the Nvidia website. 3. Build the Docker image and run it: into the directory and run the following commands: Or if you want to run the demo without CUDA support, run the following command: By default, is launched with the option . Visit to access the web UI or replace with the machine's name to access it from the network. will launch docker-compose using either the docker-compose-cuda.yml or docker-compose-cpu.ym config file, then it starts the demo using entrypoint.sh. !demo Usage Usage MASt3R <details> <summary> Code sample to compute matches with MASt3R for a pair of images </summary> </details> !matching example on croco pair Usage DUNE+MASt3R At the moment, you can only do two things: 1 Extract matches, following the subset of code below 2 Run the script with option <details> <summary> Code sample to compute matches with DUNE+MASt3R for a pair of images </summary> </details> Training In this section, we present a short demonstration to get started with training MASt3R. Datasets See Datasets section in DUSt3R Demo Like for the DUSt3R training demo, we're going to download and prepare the same subset of CO3Dv2 - Creative Commons Attribution-NonCommercial 4.0 International and launch the training code on it. It is the exact same process as DUSt3R. The demo model will be trained for a few epochs on a very small dataset. It will not be very good. Our Hyperparameters We didn't release all the training datasets, but here are the commands we used for training our models: Visual Localization Dataset preparation See Visloc section in DUSt3R Example Commands With you can run our visual localization experiments on Aachen-Day-Night, InLoc, Cambridge Landmarks and 7 Scenes.