<h1 align="center">LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control</h1> <div align='center'> <a href='https://github.com/cleardusk' target='blank'><strong>Jianzhu Guo</strong></a><sup> 1†</sup>&emsp; <a href='https://github.com/Mystery099' target='blank'><strong>Dingyun Zhang</strong></a><sup> 1,2</sup>&emsp; <a href='https://github.com/KwaiVGI' target='blank'><strong>Xiaoqiang Liu</strong></a><sup> 1</sup>&emsp; <a href='https://github.com/zzzweakman' target='blank'><strong>Zhizhou Zhong</strong></a><sup> 1,3</sup>&emsp; <a href='https://scholar.google.com.hk/citations?user=8k1ubAAAAAJ' target='blank'><strong>Yuan Zhang</strong></a><sup> 1</sup>&emsp; </div> <div align='center'> <a href='https://scholar.google.com/citations?user=P6MraaYAAAAJ' target='blank'><strong>Pengfei Wan</strong></a><sup> 1</sup>&emsp; <a href='https://openreview.net/profile?id=~DiZHANG3' target='blank'><strong>Di Zhang</strong></a><sup> 1</sup>&emsp; </div> <div align='center'> <sup>1 </sup>Kuaishou Technology&emsp; <sup>2 </sup>University of Science and Technology of China&emsp; <sup>3 </sup>Fudan University&emsp; </div> <div align='center'> <small><sup></sup> Equal contributions</small> <small><sup>†</sup> Project lead</small> </div> <br> <!-- ===== LivePortrait – Quick Start & Links ===== --> <div align="center"> <!-- 🚀 Quick Start buttons --> <p> <a href="https://huggingface.co/cleardusk/LivePortrait-Windows/blob/main/LivePortrait-Windows-v20240829.zip" target="blank"><img src="https://img.shields.io/badge/🖥 Windows Installer-v20240829-00BFFF?style=for-the-badge&logo=windows&logoColor=white" alt="Windows one-click installer"></a>&nbsp; <a href="https://huggingface.co/spaces/KwaiVGI/liveportrait" target="blank"><img src="https://img.shields.io/badge/🌐 Try Online Demo-FF6F00?style=for-the-badge&logo=huggingface&logoColor=white" alt="HuggingFace online demo"></a> </p> <!-- 📄 Paper / project / GitHub stats --> <p> <a href="https://arxiv.org/pdf/2407.03168" target="blank"><img src="https://img.shields.io/badge/arXiv-LivePortrait-red" alt="arXiv link"></a>&nbsp; <a href="https://liveportrait.github.io" target="blank"><img src="https://img.shields.io/badge/Project-Homepage-green" alt="project homepage"></a>&nbsp; <a href="https://huggingface.co/spaces/KwaiVGI/liveportrait" target="blank"><img src="https://img.shields.io/badge/🤗 Hugging Face-Spaces-blue" alt="HF space"></a>&nbsp; <a href="https://hellogithub.com/repository/bed652ef02154dd7a434e0720125639e" target="blank"><img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=bed652ef02154dd7a434e0720125639e&claimuid=XyBT2K9QJ7RZhej&theme=small" alt="Featured by HelloGitHub"></a>&nbsp; <a href="https://github.com/KwaiVGI/LivePortrait" target="blank"><img src="https://img.shields.io/github/stars/KwaiVGI/LivePortrait?style=social" alt="GitHub stars"></a> </p> <!-- 🌏 Language switch --> <p><strong>English</strong> | <a href="./readmezhcn.md"><strong>简体中文</strong></a></p> <!-- 🎬 Showcase GIF --> <p><img src="./assets/docs/showcase2.gif" alt="LivePortrait showcase GIF"></p> <p>🔥 For more results, visit our <a href="https://liveportrait.github.io/" target="blank"><strong>homepage</strong></a> 🔥</p> </div> <!-- ===== /LivePortrait ===== --> 🔥 Updates - : 🌍 Over the past year, LivePortrait has 🚀 become an efficient portrait-animation humans, cats and dogs solution adopted by major video platforms—Kuaishou, Douyin, Jianying, WeChat Channels—as well as numerous startups and creators. 🎉 - : 🐶 We updated a new version of the Animals model with more data, see here. - : ❗ We have updated the versions of the and libraries to avoid security vulnerabilities. Details here. - : 📦 We update the Windows one-click installer and support auto-updates, see changelog. - : 🖼️ We support image driven mode and regional control. For details, see here. - : 🎨 We support precise portrait editing in the Gradio interface, inspired by ComfyUI-AdvancedLivePortrait. See here. - : 📦 Windows users can now download the one-click installer for Humans mode and Animals mode now! For details, see here. - : 😸 We released a version of the Animals model, along with several other updates and improvements. Check out the details here! - : 📦 Windows users can now download the package from HuggingFace. Simply unzip and double-click to enjoy! - : 🎨 We support pose editing for source portraits in the Gradio interface. We’ve also lowered the default detection threshold to increase recall. Have fun! - : ✨ We support 🎞️ portrait video editing aka v2v! More to see here. - : 🍎 We support macOS with Apple Silicon, modified from jeethu's PR 143. - : 💪 We support audio and video concatenating, driving video auto-cropping, and template making to protect privacy. More to see here. - : 🤗 We released the HuggingFace Space, thanks to the HF team and Gradio! - : 😊 We released the initial version of the inference code and models. Continuous updates, stay tuned! - : 🔥 We released the homepage and technical report on arXiv. Introduction 📖 This repo, named LivePortrait, contains the official PyTorch implementation of our paper LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control. We are actively updating and improving this repository. If you find any bugs or have suggestions, welcome to raise issues or submit pull requests PR 💖. Getting Started 🏁 1. Clone the code and prepare the environment 🛠️ > !Note > Make sure your system has https://git-scm.com/, https://anaconda.org/anaconda/conda, and https://ffmpeg.org/download.html installed. For details on FFmpeg installation, see how to install FFmpeg. For Linux 🐧 or Windows 🪟 Users X-Pose, required by Animals mode, is a dependency that needs to be installed. The step of is optional if you only want to run Humans mode. <details> <summary>Check your CUDA versions</summary> Firstly, check your current CUDA version by: Then, install the corresponding torch version. Here are examples for different CUDA versions. Visit the PyTorch Official Website for installation commands if your CUDA version is not listed: Note: On Windows systems, some higher versions of CUDA such as 12.4, 12.6, etc. may lead to unknown issues. You may consider downgrading CUDA to version 11.8 for stability. See the downgrade guide by @dimitribarbot. </details> Finally, install the remaining dependencies: For macOS  with Apple Silicon Users The X-Pose dependency does not support macOS, so you can skip its installation. While Humans mode works as usual, Animals mode is not supported. Use the provided requirements file for macOS with Apple Silicon: 2. Download pretrained weights 📥 The easiest way to download the pretrained weights is from HuggingFace: If you cannot access to Huggingface, you can use hf-mirror to download: Alternatively, you can download all pretrained weights from Google Drive or Baidu Yun. Unzip and place them in . Ensuring the directory structure is as or contains this. 3. Inference 🚀 Fast hands-on humans 👤 If the script runs successfully, you will get an output mp4 file named . This file includes the following results: driving video, input image or video, and generated result. <p align="center"> <img src="./assets/docs/inference.gif" alt="image"> </p> Or, you can change the input by specifying the and arguments: Fast hands-on animals 🐱🐶 Animals mode is ONLY tested on Linux and Windows with NVIDIA GPU. You need to build an OP named first refer to the <a href="for-linux--or-windows--users">Check your CUDA versions</a> if needed, which is used by X-Pose, a general keypoint detection framework. Then If the script runs successfully, you will get an output mp4 file named . <p align="center"> <img src="./assets/docs/inference-animals.gif" alt="image"> </p> Driving video auto-cropping 📢📢📢 > !IMPORTANT > To use your own driving video, we recommend: ⬇️ > - Crop it to a 1:1 aspect ratio e.g., 512x512 or 256x256 pixels, or enable auto-cropping by . > - Focus on the head area, similar to the example videos. > - Minimize shoulder movement. > - Make sure the first frame of driving video is a frontal face with neutral expression. Below is an auto-cropping case by : If you find the results of auto-cropping is not well, you can modify the , options to adjust the scale and offset, or do it manually. Motion template making You can also use the auto-generated motion template files ending with to speed up inference, and protect privacy, such as: 4. Gradio interface 🤗 We also provide a Gradio <a href='https://github.com/gradio-app/gradio'><img src='https://img.shields.io/github/stars/gradio-app/gradio'></a> interface for a better experience, just run by: We also provide a Gradio interface of animals mode, which is only tested on Linux with NVIDIA GPU: You can specify the , , arguments to satisfy your needs! 🚀 We also provide an acceleration option . The first-time inference triggers an optimization process about one minute, making subsequent inferences 20-30% faster. Performance gains may vary with different CUDA versions. Note: This method is not supported on Windows and macOS. Or, try it out effortlessly on HuggingFace 🤗 5. Inference speed evaluation 🚀🚀🚀 We have also provided a script to evaluate the inference speed of each module: The results are here. Community Resources 🤗 Discover the invaluable resources contributed by our community to enhance your LivePortrait experience. Community-developed Projects | Repo | Description | Author / Links | |------|------|--------| | ditto-talkinghead | Real-time audio-driven talking head. | ArXiv, Homepage | | FasterLivePortrait | Faster real-time version using TensorRT. | @warmshao | | AdvancedLivePortrait-WebUI | Dedicated gradio based WebUI started from ComfyUI-AdvancedLivePortrait. | @jhj0517 | | FacePoke | A real-time head transformation app, controlled by your mouse! | @jbilcke-hf | | FaceFusion | FaceFusion 3.0 integregates LivePortrait as and processors. | @henryruhs | | sd-webui-live-portrait | WebUI extension of LivePortrait, adding atab to the original Stable Diffusion WebUI to benefit from LivePortrait features. | @dimitribarbot | | ComfyUI-LivePortraitKJ | A ComfyUI node to use LivePortrait, with MediaPipe as as an alternative to Insightface. | @kijai | | ComfyUI-AdvancedLivePortrait | A faster ComfyUI node with real-time preview that has inspired many other community-developed tools and projects. | @PowerHouseMan | | comfyui-liveportrait | A ComfyUI node to use LivePortrait, supporting multi-faces, expression interpolation etc, with a tutorial. | @shadowcz007 | Playgrounds, 🤗 HuggingFace Spaces and Others - FacePoke Space - Expression Editor Space - Expression Editor Replicate - Face Control Realtime Demo on FAL - Replicate Playground - Nuke can use LivePortrait through CompyUI node, details here - LivePortrait lives on Poe Video Tutorials - Workflow of LivePortrait Video to Video by @curiousrefuge - Google Colab tutorial by @Planet Ai - Paper reading by @TwoMinutePapers - ComfyUI Advanced LivePortrait by TutoView - LivePortarit exploration and A deep dive into LivePortrait by TheoreticallyMedia - LivePortrait hands-on tutorial by @AI Search - ComfyUI tutorial by @Sebastian Kamph - A tutorial on BiliBili And so MANY amazing contributions from our community, too many to list them all 💖 Acknowledgements 💐 We would like to thank the contributors of FOMM, Open Facevid2vid, SPADE, InsightFace and X-Pose repositories, for their open research and contributions. Ethics Considerations 🛡️ Portrait animation technologies come with social risks, particularly the potential for misuse in creating deepfakes. To mitigate these risks, it’s crucial to follow ethical guidelines and adopt responsible usage practices. At present, the synthesized results contain visual artifacts that may help in detecting deepfakes. Please note that we do not assume any legal responsibility for the use of the results generated by this project. Citation 💖 If you find LivePortrait useful for your project or research, welcome to 🌟 this repo and cite our work using the following BibTeX: Long live in arXiv. Contact 📧 Jianzhu Guo 郭建珠; guojianzhu1994@gmail.com Star History 🌟 <details> <summary>Click to view Star chart</summary> <p align="center"> <a href="https://www.star-history.com/KwaiVGI/LivePortrait&Timeline" target="blank"> <picture> <source media="prefers-color-scheme: dark" srcset="https://api.star-history.com/svg?repos=KwaiVGI/LivePortrait&type=Timeline&theme=dark" /> <source media="prefers-color-scheme: light" srcset="https://api.star-history.com/svg?repos=KwaiVGI/LivePortrait&type=Timeline" /> <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=KwaiVGI/LivePortrait&type=Timeline" width="90%" /> </picture> </a> </p> </details>