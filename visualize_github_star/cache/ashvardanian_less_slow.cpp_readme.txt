Playing Around Less Slow Coding Practices for C++, CUDA, and Assembly Code > The benchmarks in this repository don't aim to cover every topic entirely, but they help form a mindset and intuition for performance-oriented software design. > It also provides an example of using some non-STL but de facto standard libraries in C++, importing them via CMake and compiling from source. > For higher-level abstractions and languages, check out https://github.com/ashvardanian/lessslow.rs and https://github.com/ashvardanian/lessslow.py. > I needed many of these measurements to reconsider my own coding habits, but hopefully they're helpful to others as well. > Most of the code is organized in very long, ordered, and nested sections â€” not necessarily the preferred form for everyone. Much of modern code suffers from common pitfalls â€” bugs, security vulnerabilities, and performance bottlenecks. University curricula and coding bootcamps tend to stick to traditional coding styles and standard features, rarely exposing the more fun, unusual, and potentially efficient design opportunities. This repository explores just that. !Less Slow C++ The code leverages C++20 and CUDA features and is designed primarily for GCC, Clang, and NVCC compilers on Linux, though it may work on other platforms. The topics range from basic micro-kernels executing in a few nanoseconds to more complex constructs involving parallel algorithms, coroutines, and polymorphism. Some of the highlights include: - 100x cheaper random inputs?! Discover how input generation sometimes costs more than the algorithm. - 1% error in trigonometry at 1/40 cost: Approximate STL functions like https://en.cppreference.com/w/cpp/numeric/math/sin in just 3 lines of code. - 4x faster lazy-logic with custom https://en.cppreference.com/w/cpp/ranges and iterators! - Compiler optimizations beyond : Learn about less obvious flags and techniques for another 2x speedup. - Multiplying matrices? Check how a 3x3x3 GEMM can be 70% slower than 4x4x4, despite 60% fewer ops. - Scaling AI? Measure the gap between theoretical ALU throughput and your BLAS. - How many if conditions are too many? Test your CPU's branch predictor with just 10 lines of code. - Prefer recursion to iteration? Measure the depth at which your algorithm will https://en.wikipedia.org/wiki/Segmentationfault. - Why avoid exceptions? Take or https://en.cppreference.com/w/cpp/utility/variant-like ADTs? - Scaling to many cores? Learn how to use OpenMP, Intel's oneTBB, or your custom thread pool. - How to handle JSON avoiding memory allocations? Is it easier with C++ 20 or old-school C 99 tools? - How to properly use STL's associative containers with custom keys and transparent comparators? - How to beat a hand-written parser with https://en.cppreference.com/w/cpp/language/consteval RegEx engines? - Is the pointer size really 64 bits and how to exploit pointer-tagging? - How many packets is UDP dropping and how to serve web requests in https://en.wikipedia.org/wiki/Iouring from user-space? - Scatter and Gather for 50% faster vectorized disjoint memory operations. - Intel's oneAPI vs Nvidia's CCCL? What's so special about and ? - CUDA C++, PTX Intermediate Representations, and SASS, and how do they differ from CPU code? - How to choose between intrinsics, inline , and separate files for your performance-critical code? - Tensor Cores & Memory differences on CPUs, and Volta, Ampere, Hopper, and Blackwell GPUs! - How coding FPGA differs from GPU and what is High-Level Synthesis, Verilog, and VHDL? ðŸ”œ 36 - What are Encrypted Enclaves and what's the latency of Intel SGX, AMD SEV, and ARM Realm? ðŸ”œ 31 To read, jump to the source file and read the code snippets and comments. Keep in mind, that most modern IDEs have a navigation bar to help you view and jump between sections. Follow the instructions below to run the code in your environment and compare it to the comments as you read through the source. Running the Benchmarks The project aims to be compatible with GCC, Clang, and MSVC compilers on Linux, MacOS, and Windows. That said, to cover the broadest functionality, using GCC on Linux is recommended: - If you are on Windows, it's recommended that you set up a Linux environment using WSL. - If you are on MacOS, consider using the non-native distribution of Clang from Homebrew or MacPorts. - If you are on Linux, make sure to install CMake and a recent version of GCC or Clang compilers to support C++20 features. If you are familiar with C++ and want to review code and measurements as you read, you can clone the repository and execute the following commands. The build will pull and compile several third-party dependencies from the source: - Google's Benchmark is used for profiling. - Intel's oneTBB is used as the Parallel STL backend. - Meta's libunifex is used for senders & executors. - Eric Niebler's range-v3 replaces . - Victor Zverovich's fmt replaces . - Ash Vardanian's StringZilla replaces . - Hana DusÃ­kovÃ¡'s CTRE replaces . - Niels Lohmann's json is used for JSON deserialization. - Yaoyuan Guo's yyjson for faster JSON processing. - Google's Abseil replaces STL's associative containers. - Lewis Baker's cppcoro implements C++20 coroutines. - Jens Axboe's liburing to simplify Linux kernel-bypass. - Chris Kohlhoff's ASIO as a networking TS extension. - Nvidia's CCCL for GPU-accelerated algorithms. - Nvidia's CUTLASS for GPU-accelerated Linear Algebra. To build without Parallel STL, Intel TBB, BLAS, and CUDA: To build on MacOS, pulling key dependencies from Homebrew: To control the output or run specific benchmarks, use the following flags: To enhance stability and reproducibility, disable Simultaneous Multi-Threading SMT on your CPU and use the flag, which shuffles and interleaves benchmarks as described here. Google Benchmark supports User-Requested Performance Counters through . Note that collecting these may require privileges. Alternatively, use the Linux tool for performance counter collection: Project Structure The primary file of this repository is clearly the C++ file with CPU-side code. Several other files for different hardware-specific optimizations are created: Memes and References Educational content without memes?! Come on! <table> <tr> <td><img src="https://github.com/ashvardanian/ashvardanian/blob/master/memes/ieee764-vs-gnu-compiler.jpg?raw=true" alt="IEEE 754 vs GNU Compiler"></td> <td><img src="https://github.com/ashvardanian/ashvardanian/blob/master/memes/no-easter-bunny-no-free-abstractions.jpg?raw=true" alt="No Easter Bunny, No Free Abstractions"></td> </tr> </table> Google Benchmark Functionality This benchmark suite uses most of the features provided by Google Benchmark. If you write a lot of benchmarks and avoid going to the full User Guide, here is a condensed list of the most useful features: - - Pass multiple arguments to parameterized benchmarks - - Register a basic benchmark function - - Create variants of benchmarks with different captured values - - Specify thread-averaged counters - - Prevent compiler from optimizing away operations - - Force memory synchronization - - Specify and validate algorithmic complexity - - Set input size for complexity calculations - - Calculate custom statistics across runs - - Control exact number of iterations - - Set minimum benchmark duration - - To warm up the data caches - - Assign custom benchmark names - - Profile for a range of input sizes - - Set multiplier between range values - - Show only aggregated statistics - - Create custom performance counters - , - Control timing measurement - - Record number of bytes processed - - Skip benchmark with error message - - Run benchmark with specified number of threads - - Set time unit for reporting - - Measure real time instead of CPU time - - To feed custom timings for GPU and IO benchmarks