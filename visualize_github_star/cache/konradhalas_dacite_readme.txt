!https://user-images.githubusercontent.com/1078369/212840759-174c0f2b-d446-4c3a-b97c-67a0b912e7f6.png dacite !Build Statushttps://travis-ci.org/konradhalas/dacite !Coverage Statushttps://coveralls.io/github/konradhalas/dacite?branch=master !Licensehttps://pypi.python.org/pypi/dacite/ !Versionhttps://pypi.python.org/pypi/dacite/ !Python versionshttps://pypi.python.org/pypi/dacite/ !Code style: blackhttps://github.com/ambv/black This module simplifies creation of data classes PEP 557pep-557 from dictionaries. Installation To install dacite, simply use : Requirements Minimum Python version supported by is 3.7. Quick start Features Dacite supports following features: - nested structures - basic type checking - optional fields i.e. - unions - generics - forward references - collections - custom type hooks - case conversion Motivation Passing plain dictionaries as a data container between your functions or methods isn't a good practice. Of course you can always create your custom class instead, but this solution is an overkill if you only want to merge a few fields within a single object. Fortunately Python has a good solution to this problem - data classes. Thanks to decorator you can easily create a new custom type with a list of given fields in a declarative manner. Data classes support type hints by design. However, even if you are using data classes, you have to create their instances somehow. In many such cases, your input is a dictionary - it can be a payload from a HTTP request or a raw data from a database. If you want to convert those dictionaries into data classes, is your best friend. This library was originally created to simplify creation of type hinted data transfer objects DTO which can cross the boundaries in the application architecture. It's important to mention that is not a data validation library. There are dozens of awesome data validation projects and it doesn't make sense to duplicate this functionality within . If you want to validate your data first, you should combine with one of data validation library. Please check Use Case section for a real-life example. Usage Dacite is based on a single function - . This function takes 3 parameters: - - data class type - - dictionary of input data - optional - configuration of the creation process, instance of class Configuration is a data class with following fields: - - - - - - - The examples below show all features of function and usage of all parameters. Nested structures You can pass a data with nested dictionaries and it will create a proper result. Optional fields Whenever your data class has a field and you will not provide input data for this field, it will take the value. Unions If your field can accept multiple types, you should use . Dacite will try to match data with provided types one by one. If none will match, it will raise exception. Collections Dacite supports fields defined as collections. It works for both - basic types and data classes. Generics Dacite supports generics: multi-generic dataclasses, but also dataclasses that inherit from a generic dataclass, or dataclasses that have a generic dataclass field. Type hooks You can use argument if you want to transform the input data of a data class field with given type into the new value. You have to pass a following mapping: , where is a . If a data class field type is a you can pass both - or just - as a key in . The same with generic collections, e.g. when a field has type you can use to transform whole collection or to transform each item. Casting It's a very common case that you want to create an instance of a field type from the input data with just calling your type with the input value. Of course you can use to achieve this goal but is an easier and more expressive way. It also works with base classes - if is a base class of type , all fields of type will be also "casted". Forward References Definition of forward references can be passed as a mapping to . This dict is passed to as the param when evaluating each field's type. Type checking If you want to trade-off type checking for speed, you can disabled type checking by setting to . Strict mode By default ignores additional keys not matching data class field in the input data. If you want change this behaviour set to . In case of unexpected key will raise exception. Strict unions match allows to define multiple possible types for a given field. By default is trying to find the first matching type for a provided data and it returns instance of this type. It means that it's possible that there are other matching types further on the types list. With only a single match is allowed, otherwise raises . Convert key You can pass a callable to the configuration parameter to convert camelCase to snakecase. Exceptions Whenever something goes wrong, will raise adequate exception. There are a few of them: - - raised when a type of a input value does not match with a type of a data class field - - raised when you don't provide a value for a required field - - raised when provided data does not match any type of - - raised when undefined forward reference encountered in dataclass - - raised when mode is enabled and the input data has not matching keys - - raised when mode is enabled and the input data has ambiguous match Development First of all - if you want to submit your pull request, thank you very much! I really appreciate your support. Please remember that every new feature, bug fix or improvement should be tested. 100% code coverage is a must-have. We are using a few static code analysis tools to increase the code quality , , . Please make sure that you are not generating any errors/warnings before you submit your PR. You can find current configuration in directory. Last but not least, if you want to introduce new feature, please discuss it first within an issue. How to start Clone repository: Create and activate virtualenv in the way you like: Install all dependencies: And, optionally but recommended, install pre-commit hook for black: To run tests you just have to fire: Performance testing is a small library, but its use is potentially very extensive. Thus, it is crucial to ensure good performance of the library. We achieve that with the help of library, and a suite of dedicated performance tests which can be found in the directory. The CI process runs these tests automatically, but they can also be helpful locally, while developing the library. Whenever you run command, a new benchmark report is saved to directory. You can easily compare these reports by running: , which will load all the runs and display them in a table, where you can compare the performance of each run. You can even specify which particular runs you want to compare, e.g. . Use case There are many cases when we receive "raw" data Python dicts as a input to our system. HTTP request payload is a very common use case. In most web frameworks we receive request data as a simple dictionary. Instead of passing this dict down to your "business" code, it's a good idea to create something more "robust". Following example is a simple app - it has single endpoint. You can use this endpoint to "create" product in your system. Our core function expects data class as a parameter. Thanks to we can easily build such data class from request payload. What if we want to validate our data e.g. check if has 6 characters? Such features are out of scope of but we can easily combine it with one of data validation library. Let's try with marshmallow. First of all we have to define our data validation schemas: And use them within our endpoint: Still helps us to create data class from "raw" dict with validated data. Cache uses some LRU caching to improve its performance where possible. To use the caching utility: The caching is completely transparent from the interface perspective. Changelog Follow updates in CHANGELOGchangelog. Authors Created by Konrad Ha≈Çashalas-homepage. pep-557: https://www.python.org/dev/peps/pep-0557/ halas-homepage: https://konradhalas.pl changelog: https://github.com/konradhalas/dacite/blob/master/CHANGELOG.md