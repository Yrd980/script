<div align="center" style="border-bottom: none"> <h1> <img src="docs/Meetily-6.png" style="border-radius: 10px;" /> <br> Your AI-Powered Meeting Assistant </h1> <a href="https://trendshift.io/repositories/13272" target="blank"><img src="https://trendshift.io/api/badge/repositories/13272" alt="Zackriya-Solutions%2Fmeeting-minutes | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a> <br> <br> <a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases/"><img src="https://img.shields.io/badge/PreRelease-Link-brightgreen" alt="Pre-Release"></a> <a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"><img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/zackriya-solutions/meeting-minutes?style=flat"> </a> <a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"> <img alt="GitHub Downloads all assets, all releases" src="https://img.shields.io/github/downloads/zackriya-solutions/meeting-minutes/total?style=plastic"> </a> <a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"><img src="https://img.shields.io/badge/License-MIT-blue" alt="License"></a> <a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"><img src="https://img.shields.io/badge/SupportedOS-macOS,Windows-white" alt="Supported OS"></a> <a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"><img alt="GitHub Tag" src="https://img.shields.io/github/v/tag/zackriya-solutions/meeting-minutes?includeprereleases&color=yellow"> </a> <br> <h3> <br> Open source Ai Assistant for taking meeting notes </h3> <p align="center"> Get latest <a href="https://www.zackriya.com/meetily-subscribe/"><b>Product updates</b></a> <br><br> <a href="https://meetily.zackriya.com"><b>Website</b></a> â€¢ <a href="https://in.linkedin.com/company/zackriya-solutions"><b>Authors</b></a> â€¢ <a href="https://discord.gg/crRymMQBFH"><b>Discord Channel</b></a> </p> <p align="center"> An AI-Powered Meeting Assistant that captures live meeting audio, transcribes it in real-time, and generates summaries while ensuring user privacy. Perfect for teams who want to focus on discussions while automatically capturing and organizing meeting content without the need for external servers or complex infrastructure. </p> <p align="center"> <img src="docs/demosmall.gif" width="650" alt="Meetily Demo" /> <br> <a href="https://youtu.be/5kQ5Wlahuk">View full Demo Video</a> </p> </div> Table of Contents - Overview - Features - System Architecture - Core Components - Deployment Architecture - Prerequisites - Setup Instructions - Windows OS - Frontend Setup - Backend Setup - macOS - Frontend Setup - Backend Setup - Development Setup - Whisper Model Selection - Known Issues - LLM Integration - Supported Providers - Configuration - Troubleshooting - Backend Issues - Frontend Issues - Uninstallation - Development Guidelines - Contributing - License - Introducing Subscription - Contributions - Acknowledgments - Star History Overview An AI-powered meeting assistant that captures live meeting audio, transcribes it in real-time, and generates summaries while ensuring user privacy. Perfect for teams who want to focus on discussions while automatically capturing and organizing meeting content. Why? While there are many meeting transcription tools available, this solution stands out by offering: - Privacy First: All processing happens locally on your device - Cost Effective: Uses open-source AI models instead of expensive APIs - Flexible: Works offline, supports multiple meeting platforms - Customizable: Self-host and modify for your specific needs - Intelligent: Built-in knowledge graph for semantic search across meetings Features âœ… Modern, responsive UI with real-time updates âœ… Real-time audio capture microphone + system audio âœ… Live transcription using locally-running Whisper âœ… Local processing for privacy âœ… Packaged the app for macOS and Windows âœ… Rich text editor for notes ðŸš§ Export to Markdown/PDF/HTML ðŸš§ Obsidian Integration ðŸš§ Speaker diarization --- System Architecture <p align="center"> <img src="docs/HighLevel.jpg" width="900" alt="Meetily High Level Architecture" /> </p> Core Components 1. Audio Capture Service - Real-time microphone/system audio capture - Audio preprocessing pipeline - Built with Rust experimental and Python 2. Transcription Engine - Whisper.cpp for local transcription - Supports multiple model sizes tiny->large - GPU-accelerated processing 3. LLM Orchestrator - Unified interface for multiple providers - Automatic fallback handling - Chunk processing with overlap - Model configuration: 4. Data Services - ChromaDB: Vector store for transcript embeddings - SQLite: Process tracking and metadata storage Deployment Architecture - Frontend: Tauri app + Next.js packaged executables - Backend: Python FastAPI: - Transcript workers - LLM inference Prerequisites - Node.js 18+ - Python 3.10+ - FFmpeg - Rust 1.65+ for experimental features - Cmake 3.22+ for building the frontend - For Windows: Visual Studio Build Tools with C++ development workload Setup Instructions Windows OS 1. Frontend Setup Option 1: Using the Setup Executable .exe Recommended 1. Download the file 2. Double-click the installer to run it 3. Follow the on-screen instructions to complete the installation 4. The application will be available on your desktop Note: Windows may display a security warning. To bypass this: - Click and choose , or - Right-click on the installer .exe, select Properties, and check the Unblock checkbox at the bottom <p align="center"> <img src="https://github.com/user-attachments/assets/f2a2655d-9881-42ed-88aa-357a1f5b6118" width="300" alt="Windows Security Warning" /> </p> Option 2: Using the MSI Installer .msi 1. Download the file 2. Double-click the MSI file to run it 3. Follow the installation wizard to complete the setup 4. The application will be installed and available on your desktop Provide necessary permissions for audio capture and microphone access. 2. Backend Setup <p align="center"> <a href="https://www.youtube.com/watch?v=Tu8wXgoaDE"> <img src="https://img.youtube.com/vi/Tu8wXgoaDE/0.jpg" alt="Windows Security Warning" /> </a> </p> Option 1: Manual Setup 1. Clone the repository: 2. Build dependencies: 3. Start the backend servers: Option 2: Docker Setup including ARM64/Snapdragon Docker Configuration Options The Docker setup for both macOS and Windows allows you to configure: - Whisper model selection tiny, base, small, medium, large-v3, etc. - Language preference auto-detection or specific language - Logging level For macOS: 1. Frontend Setup Go to the releases page and download the latest version. Option 1: Using Homebrew Recommended > Note : This step installs the backend server and the frontend app. > Once the backend and the frontend are started, you can open the application from the Applications folder. Option 2: Manual Installation - Download the file - Extract the file - Double-click the file inside the extracted folder - Drag the application to your Applications folder - Execute the following command in terminal to remove the quarantine attribute: Provide necessary permissions for audio capture and microphone access. 2. Backend Setup Option 1: Using Homebrew Recommended Option 2: Manual Setup Development Setup Whisper Model Selection When setting up the backend either via Homebrew, manual installation, or Docker, you can choose from various Whisper models based on your needs: 1. Standard models balance of accuracy and speed: - tiny, base, small, medium 2. English-optimized models faster for English content: - tiny.en, base.en, small.en, medium.en 3. Advanced models for special needs: - large-v3, large-v3-turbo - small.en-tdrz with speaker diarization 4. Quantized models reduced size, slightly lower quality: - tiny-q51, base-q51, small-q51, medium-q50 Known issues - Smaller LLMs can hallucinate, making summarization quality poor; Please use model above 32B parameter size - Backend build process requires CMake, C++ compiler, etc. Making it harder to build - Backend build process requires Python 3.10 or newer - Frontend build process requires Node.js LLM Integration The backend supports multiple LLM providers through a unified interface. Current implementations include: Supported Providers - Anthropic Claude models - Groq Llama3.2 90 B - Ollama Local models that supports function calling Troubleshooting Backend Issues Model Problems If you encounter issues with the Whisper model: Server Connection Issues If the server fails to start: 1. Check if ports 8178 and 5167 are available: 2. Verify that FFmpeg is installed correctly: 3. Check the logs for specific error messages when running 4. Try running the Whisper server manually: Frontend Issues If the frontend application doesn't connect to the backend: 1. Ensure the backend server is running 2. Check if the application can access localhost:5167 3. Restart the application after starting the backend If the application fails to launch: Uninstallation To completely remove Meetily: Development Guidelines - Follow the established project structure - Write tests for new features - Document API changes - Use type hints in Python code - Follow ESLint configuration for JavaScript/TypeScript Contributing 1. Fork the repository 2. Create a feature branch 3. Submit a pull request License MIT License - Feel free to use this project for your own purposes. Introducing Subscription We are planning to add a subscription option so that you don't have to run the backend on your own server. This will help you scale better and run the service 24/7. This is based on a few requests we received. If you are interested, please fill out the form here. Contributions Thanks for all the contributions. Our community is what makes this project possible. Below is the list of contributors: <a href="https://github.com/zackriya-solutions/meeting-minutes/graphs/contributors"> <img src="https://contrib.rocks/image?repo=zackriya-solutions/meeting-minutes" /> </a> We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the CONTRIBUTING file. Acknowledgments - We borrowes some code from Whisper.cpp - We borrowes some code from Screenpipe Star History !Star History Charthttps://star-history.com/Zackriya-Solutions/meeting-minutes&Date