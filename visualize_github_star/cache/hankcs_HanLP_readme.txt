<h2 align="center">HanLP: Han Language Processing</h2> <div align="center"> <a href="https://github.com/hankcs/HanLP/actions/workflows/unit-tests.yml"> <img alt="Unit Tests" src="https://github.com/hankcs/hanlp/actions/workflows/unit-tests.yml/badge.svg?branch=master"> </a> <a href="https://pypi.org/project/hanlp/"> <img alt="PyPI Version" src="https://img.shields.io/pypi/v/hanlp?color=blue"> </a> <a href="https://pypi.org/project/hanlp/"> <img alt="Python Versions" src="https://img.shields.io/pypi/pyversions/hanlp?colorB=blue"> </a> <a href="https://pepy.tech/project/hanlp"> <img alt="Downloads" src="https://static.pepy.tech/badge/hanlp"> </a> <a href="https://mybinder.org/v2/gh/hankcs/HanLP/doc-zh?filepath=plugins%2Fhanlpdemo%2Fhanlpdemo%2Fzh%2Ftutorial.ipynb"> <img alt="在线运行" src="https://mybinder.org/badgelogo.svg"> </a> </div> <h4 align="center"> <a href="https://github.com/hankcs/HanLP/tree/master">English</a> | <a href="https://github.com/hankcs/HanLP/tree/doc-ja">日本語</a> | <a href="https://hanlp.hankcs.com/docs/">文档</a> | <a href="https://bbs.hankcs.com/t/topic/3940">论文</a> | <a href="https://bbs.hankcs.com/">论坛</a> | <a href="https://github.com/wangedison/hanlp-jupyterlab-docker">docker</a> | <a href="https://mybinder.org/v2/gh/hankcs/HanLP/doc-zh?filepath=plugins%2Fhanlpdemo%2Fhanlpdemo%2Fzh%2Ftutorial.ipynb">▶️在线运行</a> </h4> 面向生产环境的多语种自然语言处理工具包，基于PyTorch和TensorFlow 2.x双引擎，目标是普及落地最前沿的NLP技术。HanLP具备功能完善、精度准确、性能高效、语料时新、架构清晰、可自定义的特点。 !demohttps://mybinder.org/v2/gh/hankcs/HanLP/doc-zh?filepath=plugins%2Fhanlpdemo%2Fhanlpdemo%2Fzh%2Ftutorial.ipynb 借助世界上最大的多语种语料库，HanLP2.1支持包括简繁中英日俄法德在内的130种语言上的10种联合任务以及多种单任务。HanLP预训练了十几种任务上的数十个模型并且正在持续迭代语料库与模型： <div align="center"> | 功能 | RESTful | 多任务 | 单任务 | 模型 | 标注标准 | | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | | 分词 | 教程 | 教程 | 教程 | tok | 粗分、细分 | | 词性标注 | 教程 | 教程 | 教程 | pos | CTB、PKU、863 | | 命名实体识别 | 教程 | 教程 | 教程 | ner | PKU、MSRA、OntoNotes | | 依存句法分析 | 教程 | 教程 | 教程 | dep | SD、UD、PMT | | 成分句法分析 | 教程 | 教程 | 教程 | con | Chinese Tree Bank | | 语义依存分析 | 教程 | 教程 | 教程 | sdp | CSDP | | 语义角色标注 | 教程 | 教程 | 教程 | srl | Chinese Proposition Bank | | 抽象意义表示 | 教程 | 暂无 | 教程 | amr | CAMR | | 指代消解 | 教程 | 暂无 | 暂无 | 暂无 | OntoNotes | | 语义文本相似度 | 教程 | 暂无 | 教程 | sts | 暂无 | | 文本风格转换 | 教程 | 暂无 | 暂无 | 暂无 | 暂无 | | 关键词短语提取 | 教程 | 暂无 | 暂无 | 暂无 | 暂无 | | 抽取式自动摘要 | 教程 | 暂无 | 暂无 | 暂无 | 暂无 | | 生成式自动摘要 | 教程 | 暂无 | 暂无 | 暂无 | 暂无 | | 文本语法纠错 | 教程 | 暂无 | 暂无 | 暂无 | 暂无 | | 文本分类 | 教程 | 暂无 | 暂无 | 暂无 | 暂无 | | 情感分析 | 教程 | 暂无 | 暂无 | 暂无 | | | 语种检测 | 教程 | 暂无 | 教程 | 暂无 | ISO 639-1编码 | </div> - 词干提取、词法语法特征提取请参考英文教程；词向量和完形填空请参考相应文档。 - 简繁转换、拼音、新词发现、文本聚类请参考1.x教程。 量体裁衣，HanLP提供RESTful和native两种API，分别面向轻量级和海量级两种场景。无论何种API何种语言，HanLP接口在语义上保持一致，在代码上坚持开源。如果您在研究中使用了HanLP，请引用我们的EMNLP论文。 轻量级RESTful API 仅数KB，适合敏捷开发、移动APP等场景。简单易用，无需GPU配环境，秒速安装。语料更多、模型更大、精度更高，强烈推荐。服务器GPU算力有限，匿名用户配额较少，建议申请免费公益API秘钥。 Python 创建客户端，填入服务器地址和秘钥： Golang 安装 ，创建客户端，填入服务器地址和秘钥： Java 在中添加依赖： 创建客户端，填入服务器地址和秘钥： 快速上手 无论何种开发语言，调用接口，传入一篇文章，得到HanLP精准的分析结果。 更多功能包括语义相似度、风格转换、指代消解等，请参考文档和测试用例。 海量级native API 依赖PyTorch、TensorFlow等深度学习技术，适合专业NLP工程师、研究者以及本地海量数据场景。要求Python 3.6至3.10，支持Windows，推荐nix。可以在CPU上运行，推荐GPU/TPU。安装PyTorch版： - HanLP每次发布都通过了Linux、macOS和Windows上Python3.6至3.10的单元测试，不存在安装问题。 HanLP发布的模型分为多任务和单任务两种，多任务速度快省显存，单任务精度高更灵活。 多任务模型 HanLP的工作流程为加载模型然后将其当作函数调用，例如下列联合多任务模型： Native API的输入单位为句子，需使用多语种分句模型或基于规则的分句函数先行分句。RESTful和native两种API的语义设计完全一致，用户可以无缝互换。简洁的接口也支持灵活的参数，常用的技巧有： - 灵活的任务调度，任务越少，速度越快，详见教程。在内存有限的场景下，用户还可以删除不需要的任务达到模型瘦身的效果。 - 高效的trie树自定义词典，以及强制、合并、校正3种规则，请参考demo和文档。规则系统的效果将无缝应用到后续统计模型，从而快速适应新领域。 单任务模型 根据我们的最新研究，多任务学习的优势在于速度和显存，然而精度往往不如单任务模型。所以，HanLP预训练了许多单任务模型并设计了优雅的流水线模式将其组装起来。 更多功能，请参考demo和文档了解更多模型与用法。 输出格式 无论何种API何种开发语言何种自然语言，HanLP的输出统一为格式兼容的https://hanlp.hankcs.com/docs/api/common/document.html: 特别地，Python RESTful和native API支持基于等宽字体的可视化，能够直接将语言学结构在控制台内可视化出来： 关于标注集含义，请参考《语言学标注规范》及《格式规范》。我们购买、标注或采用了世界上量级最大、种类最多的语料库用于联合多语种多任务学习，所以HanLP的标注集也是覆盖面最广的。 训练你自己的领域模型 写深度学习模型一点都不难，难的是复现较高的准确率。下列代码展示了如何在sighan2005 PKU语料库上花6分钟训练一个超越学术界state-of-the-art的中文分词模型。 其中，由于指定了随机数种子，结果一定是。不同于那些虚假宣传的学术论文或商业项目，HanLP保证所有结果可复现。如果你有任何质疑，我们将当作最高优先级的致命性bug第一时间排查问题。 请参考demo了解更多训练脚本。 性能 <table><thead><tr><th rowspan="2">lang</th><th rowspan="2">corpora</th><th rowspan="2">model</th><th colspan="2">tok</th><th colspan="4">pos</th><th colspan="3">ner</th><th rowspan="2">dep</th><th rowspan="2">con</th><th rowspan="2">srl</th><th colspan="4">sdp</th><th rowspan="2">lem</th><th rowspan="2">fea</th><th rowspan="2">amr</th></tr><tr><th>fine</th><th>coarse</th><th>ctb</th><th>pku</th><th>863</th><th>ud</th><th>pku</th><th>msra</th><th>ontonotes</th><th>SemEval16</th><th>DM</th><th>PAS</th><th>PSD</th></tr></thead><tbody><tr><td rowspan="2">mul</td><td rowspan="2">UD2.7<br>OntoNotes5</td><td>small</td><td>98.62</td><td>-</td><td>-</td><td>-</td><td>-</td><td>93.23</td><td>-</td><td>-</td><td>74.42</td><td>79.10</td><td>76.85</td><td>70.63</td><td>-</td><td>91.19</td><td>93.67</td><td>85.34</td><td>87.71</td><td>84.51</td><td>-</td></tr><tr><td>base</td><td>98.97</td><td>-</td><td>-</td><td>-</td><td>-</td><td>90.32</td><td>-</td><td>-</td><td>80.32</td><td>78.74</td><td>71.23</td><td>73.63</td><td>-</td><td>92.60</td><td>96.04</td><td>81.19</td><td>85.08</td><td>82.13</td><td>-</td></tr><tr><td rowspan="5">zh</td><td rowspan="2">open</td><td>small</td><td>97.25</td><td>-</td><td>96.66</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>95.00</td><td>84.57</td><td>87.62</td><td>73.40</td><td>84.57</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>base</td><td>97.50</td><td>-</td><td>97.07</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>96.04</td><td>87.11</td><td>89.84</td><td>77.78</td><td>87.11</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td rowspan="3">close</td><td>small</td><td>96.70</td><td>95.93</td><td>96.87</td><td>97.56</td><td>95.05</td><td>-</td><td>96.22</td><td>95.74</td><td>76.79</td><td>84.44</td><td>88.13</td><td>75.81</td><td>74.28</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>base</td><td>97.52</td><td>96.44</td><td>96.99</td><td>97.59</td><td>95.29</td><td>-</td><td>96.48</td><td>95.72</td><td>77.77</td><td>85.29</td><td>88.57</td><td>76.52</td><td>73.76</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>ernie</td><td>96.95</td><td>97.29</td><td>96.76</td><td>97.64</td><td>95.22</td><td>-</td><td>97.31</td><td>96.47</td><td>77.95</td><td>85.67</td><td>89.17</td><td>78.51</td><td>74.10</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr></tbody></table> - 根据我们的最新研究，单任务学习的性能往往优于多任务学习。在乎精度甚于速度的话，建议使用单任务模型。 HanLP采用的数据预处理与拆分比例与流行方法未必相同，比如HanLP采用了完整版的MSRA命名实体识别语料，而非大众使用的阉割版；HanLP使用了语法覆盖更广的Stanford Dependencies标准，而非学术界沿用的Zhang and Clark 2008标准；HanLP提出了均匀分割CTB的方法，而不采用学术界不均匀且遗漏了51个黄金文件的方法。HanLP开源了一整套语料预处理脚本与相应语料库，力图推动中文NLP的透明化。 总之，HanLP只做我们认为正确、先进的事情，而不一定是流行、权威的事情。 引用 如果你在研究中使用了HanLP，请按如下格式引用： License 源代码 HanLP源代码的授权协议为 Apache License 2.0，可免费用做商业用途。请在产品说明中附加HanLP的链接和授权协议。HanLP受版权法保护，侵权必究。 自然语义（青岛）科技有限公司 HanLP从v1.7版起独立运作，由自然语义（青岛）科技有限公司作为项目主体，主导后续版本的开发，并拥有后续版本的版权。 上海林原公司 HanLP 早期得到了上海林原公司的大力支持，并拥有1.28及前序版本的版权，相关版本也曾在上海林原公司网站发布。 预训练模型 机器学习模型的授权在法律上没有定论，但本着尊重开源语料库原始授权的精神，如不特别说明，HanLP的多语种模型授权沿用CC BY-NC-SA 4.0，中文模型授权为仅供研究与教学使用。 References https://hanlp.hankcs.com/docs/references.html