<p align="center"> <img src="assets/logo.svg" style="width: 25%; height: auto;"> </p> STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking <p align="center"> | <a href="http://storm.genie.stanford.edu"><b>Research preview</b></a> | <a href="https://arxiv.org/abs/2402.14207"><b>STORM Paper</b></a>| <a href="https://www.arxiv.org/abs/2408.15232"><b>Co-STORM Paper</b></a> | <a href="https://storm-project.stanford.edu/"><b>Website</b></a> | </p> Latest News üî• - 2025/01 We add litellm integration for language models and embedding models in v1.1.0. - 2024/09 Co-STORM codebase is now released and integrated into python package v1.0.0. Run to check it out. - 2024/09 We introduce collaborative STORM Co-STORM to support human-AI collaborative knowledge curation! Co-STORM Paper has been accepted to EMNLP 2024 main conference. - 2024/07 You can now install our package with ! - 2024/07 We add to support grounding on user-provided documents, complementing existing support of search engines , . check out 58 - 2024/07 We release demo light for developers a minimal user interface built with streamlit framework in Python, handy for local development and demo hosting checkout 54 - 2024/06 We will present STORM at NAACL 2024! Find us at Poster Session 2 on June 17 or check our presentation material. - 2024/05 We add Bing Search support in rm.py. Test STORM with - we now configure the article generation part in our demo using model. - 2024/04 We release refactored version of STORM codebase! We define interface for STORM pipeline and reimplement STORM-wiki check out knowledgestorm/stormwiki to demonstrate how to instantiate the pipeline. We provide API to support customization of different language models and retrieval/search integration. !Code style: blackhttps://github.com/psf/black Overview Try STORM now! <p align="center"> <img src="assets/overview.svg" style="width: 90%; height: auto;"> </p> STORM is a LLM system that writes Wikipedia-like articles from scratch based on Internet search. Co-STORM further enhanced its feature by enabling human to collaborative LLM system to support more aligned and preferred information seeking and knowledge curation. While the system cannot produce publication-ready articles that often require a significant number of edits, experienced Wikipedia editors have found it helpful in their pre-writing stage. More than 70,000 people have tried our live research preview. Try it out to see how STORM can help your knowledge exploration journey and please provide feedback to help us improve the system üôè! How STORM & Co-STORM works STORM STORM breaks down generating long articles with citations into two steps: 1. Pre-writing stage: The system conducts Internet-based research to collect references and generates an outline. 2. Writing stage: The system uses the outline and references to generate the full-length article with citations. <p align="center"> <img src="assets/twostages.jpg" style="width: 60%; height: auto;"> </p> STORM identifies the core of automating the research process as automatically coming up with good questions to ask. Directly prompting the language model to ask questions does not work well. To improve the depth and breadth of the questions, STORM adopts two strategies: 1. Perspective-Guided Question Asking: Given the input topic, STORM discovers different perspectives by surveying existing articles from similar topics and uses them to control the question-asking process. 2. Simulated Conversation: STORM simulates a conversation between a Wikipedia writer and a topic expert grounded in Internet sources to enable the language model to update its understanding of the topic and ask follow-up questions. CO-STORM Co-STORM proposes a collaborative discourse protocol which implements a turn management policy to support smooth collaboration among - Co-STORM LLM experts: This type of agent generates answers grounded on external knowledge sources and/or raises follow-up questions based on the discourse history. - Moderator: This agent generates thought-provoking questions inspired by information discovered by the retriever but not directly used in previous turns. Question generation can also be grounded! - Human user: The human user will take the initiative to either 1 observe the discourse to gain deeper understanding of the topic, or 2 actively engage in the conversation by injecting utterances to steer the discussion focus. <p align="center"> <img src="assets/co-storm-workflow.jpg" style="width: 60%; height: auto;"> </p> Co-STORM also maintains a dynamic updated mind map, which organize collected information into a hierarchical concept structure, aiming to build a shared conceptual space between the human user and the system. The mind map has been proven to help reduce the mental load when the discourse goes long and in-depth. Both STORM and Co-STORM are implemented in a highly modular way using dspy. Installation To install the knowledge storm library, use . You could also install the source code which allows you to modify the behavior of STORM engine directly. 1. Clone the git repository. 2. Install the required packages. API Currently, our package support: - Language model components: All language models supported by litellm as listed here - Embedding model components: All embedding models supported by litellm as listed here - retrieval module components: , , , , , , , , , and as :star2: PRs for integrating more search engines/retrievers into knowledgestorm/rm.py are highly appreciated! Both STORM and Co-STORM are working in the information curation layer, you need to set up the information retrieval module and language model module to create their classes respectively. STORM The STORM knowledge curation engine is defined as a simple Python class. Here is an example of using You.com search engine and OpenAI models. The instance can be evoked with the simple method: - : if True, simulate conversations with difference perspectives to collect information about the topic; otherwise, load the results. - : if True, generate an outline for the topic; otherwise, load the results. - : if True, generate an article for the topic based on the outline and the collected information; otherwise, load the results. - : if True, polish the article by adding a summarization section and optionally removing duplicate content; otherwise, load the results. Co-STORM The Co-STORM knowledge curation engine is defined as a simple Python class. Here is an example of using Bing search engine and OpenAI models. The instance can be evoked with the and methods. Quick Start with Example Scripts We provide scripts in our examples folder as a quick start to run STORM and Co-STORM with different configurations. We suggest using to set up the API keys. Create a file under the root directory and add the following content: STORM examples To run STORM with family models with default configurations: Run the following command. To run STORM using your favorite language models or grounding on your own corpus: Check out examples/stormexamples/README.md. Co-STORM examples To run Co-STORM with family models with default configurations, 1. Add and to 2. Run the following command Customization of the Pipeline STORM If you have installed the source code, you can customize STORM based on your own use case. STORM engine consists of 4 modules: 1. Knowledge Curation Module: Collects a broad coverage of information about the given topic. 2. Outline Generation Module: Organizes the collected information by generating a hierarchical outline for the curated knowledge. 3. Article Generation Module: Populates the generated outline with the collected information. 4. Article Polishing Module: Refines and enhances the written article for better presentation. The interface for each module is defined in , while their implementations are instantiated in . These modules can be customized according to your specific requirements e.g., generating sections in bullet point format instead of full paragraphs. Co-STORM If you have installed the source code, you can customize Co-STORM based on your own use case 1. Co-STORM introduces multiple LLM agent types i.e. Co-STORM experts and Moderator. LLM agent interface is defined in , while its implementation is instantiated in . Different LLM agent policies can be customized. 2. Co-STORM introduces a collaborative discourse protocol, with its core function centered on turn policy management. We provide an example implementation of turn policy management through in . It can be customized and further improved. Datasets To facilitate the study of automatic knowledge curation and complex information seeking, our project releases the following datasets: FreshWiki The FreshWiki Dataset is a collection of 100 high-quality Wikipedia articles focusing on the most-edited pages from February 2022 to September 2023. See Section 2.1 in STORM paper for more details. You can download the dataset from huggingface directly. To ease the data contamination issue, we archive the source code for the data construction pipeline that can be repeated at future dates. WildSeek To study users‚Äô interests in complex information seeking tasks in the wild, we utilized data collected from the web research preview to create the WildSeek dataset. We downsampled the data to ensure the diversity of the topics and the quality of the data. Each data point is a pair comprising a topic and the user‚Äôs goal for conducting deep search on the topic. For more details, please refer to Section 2.2 and Appendix A of Co-STORM paper. The WildSeek dataset is available here. Replicate STORM & Co-STORM paper result For STORM paper experiments, please switch to the branch here. For Co-STORM paper experiments, please switch to the branch placeholder for now, will be updated soon. Roadmap & Contributions Our team is actively working on: 1. Human-in-the-Loop Functionalities: Supporting user participation in the knowledge curation process. 2. Information Abstraction: Developing abstractions for curated information to support presentation formats beyond the Wikipedia-style report. If you have any questions or suggestions, please feel free to open an issue or pull request. We welcome contributions to improve the system and the codebase! Contact person: Yijia Shao and Yucheng Jiang Acknowledgement We would like to thank Wikipedia for its excellent open-source content. The FreshWiki dataset is sourced from Wikipedia, licensed under the Creative Commons Attribution-ShareAlike CC BY-SA license. We are very grateful to Michelle Lam for designing the logo for this project and Dekun Ma for leading the UI development. Thanks to Vercel for their support of open-source software Citation Please cite our paper if you use this code or part of it in your work: