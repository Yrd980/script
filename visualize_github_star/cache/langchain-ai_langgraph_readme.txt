<picture class="github-only"> <source media="prefers-color-scheme: light" srcset="https://langchain-ai.github.io/langgraph/static/wordmarkdark.svg"> <source media="prefers-color-scheme: dark" srcset="https://langchain-ai.github.io/langgraph/static/wordmarklight.svg"> <img alt="LangGraph Logo" src="https://langchain-ai.github.io/langgraph/static/wordmarkdark.svg" width="80%"> </picture> <div> <br> </div> !Versionhttps://pypi.org/project/langgraph/ !Downloadshttps://pepy.tech/project/langgraph !Open Issueshttps://github.com/langchain-ai/langgraph/issues !Docshttps://langchain-ai.github.io/langgraph/ Trusted by companies shaping the future of agents – including Klarna, Replit, Elastic, and more – LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents. Get started Install LangGraph: Then, create an agent using prebuilt components: For more information, see the Quickstart. Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials. Core benefits LangGraph provides low-level supporting infrastructure for any long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits: - Durable execution: Build agents that persist through failures and can run for extended periods, automatically resuming from exactly where they left off. - Human-in-the-loop: Seamlessly incorporate human oversight by inspecting and modifying agent state at any point during execution. - Comprehensive memory: Create truly stateful agents with both short-term working memory for ongoing reasoning and long-term persistent memory across sessions. - Debugging with LangSmith: Gain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics. - Production-ready deployment: Deploy sophisticated agent systems confidently with scalable infrastructure designed to handle the unique challenges of stateful, long-running workflows. LangGraph’s ecosystem While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with: - LangSmith — Helpful for agent evals and observability. Debug poor-performing LLM app runs, evaluate agent trajectories, gain visibility in production, and improve performance over time. - LangGraph Platform — Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. Discover, reuse, configure, and share agents across teams — and iterate quickly with visual prototyping in LangGraph Studio. - LangChain – Provides integrations and composable components to streamline LLM application development. > !NOTE > Looking for the JS version of LangGraph? See the JS repo and the JS docs. Additional resources - Guides: Quick, actionable code snippets for topics such as streaming, adding memory & persistence, and design patterns e.g. branching, subgraphs, etc.. - Reference: Detailed reference on core classes, methods, how to use the graph and checkpointing APIs, and higher-level prebuilt components. - Examples: Guided examples on getting started with LangGraph. - LangChain Forum: Connect with the community and share all of your technical questions, ideas, and feedback. - LangChain Academy: Learn the basics of LangGraph in our free, structured course. - Templates: Pre-built reference apps for common agentic workflows e.g. ReAct agent, memory, retrieval etc. that can be cloned and adapted. - Case studies: Hear how industry leaders use LangGraph to ship AI applications at scale. Acknowledgements LangGraph is inspired by Pregel and Apache Beam. The public interface draws inspiration from NetworkX. LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.