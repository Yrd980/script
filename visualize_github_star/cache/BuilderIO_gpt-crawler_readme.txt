GPT Crawler <!-- omit from toc --> <!-- Keep these links. Translations will automatically update with the README. --> Deutsch | Español | français | 日本語 | 한국어 | Português | Русский | 中文 Crawl a site to generate knowledge files to create your own custom GPT from one or multiple URLs !Gif showing the crawl run - Example - Get started - Running locally - Clone the repository - Install dependencies - Configure the crawler - Run your crawler - Alternative methods - Running in a container with Docker - Running as an API - Upload your data to OpenAI - Create a custom GPT - Create a custom assistant - Contributing Example Here is a custom GPT that I quickly made to help answer questions about how to use and integrate Builder.io by simply providing the URL to the Builder docs. This project crawled the docs and generated the file that I uploaded as the basis for the custom GPT. Try it out yourself by asking questions about how to integrate Builder.io into a site. > Note that you may need a paid ChatGPT plan to access this feature Get started Running locally Clone the repository Be sure you have Node.js >= 16 installed. Install dependencies Configure the crawler Open config.ts and edit the and properties to match your needs. E.g. to crawl the Builder.io docs to make our custom GPT you can use: See config.ts for all available options. Here is a sample of the common configuration options: Run your crawler Alternative methods Running in a container with Docker To obtain the with a containerized execution, go into the directory and modify the as shown above. The file should be generated in the data folder. Note: the property in the file in the directory is configured to work with the container. Running as an API To run the app as an API server you will need to do an to install the dependencies. The server is written in Express JS. To run the server. to start the server. The server runs by default on port 3000. You can use the endpoint with the post request body of config json to run the crawler. The api docs are served on the endpoint and are served using swagger. To modify the environment you can copy over the to and set your values like port, etc. to override the variables for the server. Upload your data to OpenAI The crawl will generate a file called at the root of this project. Upload that to OpenAI to create your custom assistant or custom GPT. Create a custom GPT Use this option for UI access to your generated knowledge that you can easily share with others > Note: you may need a paid ChatGPT plan to create and use custom GPTs right now 1. Go to https://chat.openai.com/ 2. Click your name in the bottom left corner 3. Choose "My GPTs" in the menu 4. Choose "Create a GPT" 5. Choose "Configure" 6. Under "Knowledge" choose "Upload a file" and upload the file you generated 7. if you get an error about the file being too large, you can try to split it into multiple files and upload them separately using the option maxFileSize in the config.ts file or also use tokenization to reduce the size of the file with the option maxTokens in the config.ts file !Gif of how to upload a custom GPT Create a custom assistant Use this option for API access to your generated knowledge that you can integrate into your product. 1. Go to https://platform.openai.com/assistants 2. Click "+ Create" 3. Choose "upload" and upload the file you generated !Gif of how to upload to an assistant Contributing Know how to make this project better? Send a PR! <br> <br> <p align="center"> <a href="https://www.builder.io/m/developers"> <picture> <source media="prefers-color-scheme: dark" srcset="https://user-images.githubusercontent.com/844291/230786554-eb225eeb-2f6b-4286-b8c2-535b1131744a.png"> <img width="250" alt="Made with love by Builder.io" src="https://user-images.githubusercontent.com/844291/230786555-a58479e4-75f3-4222-a6eb-74c5af953eac.png"> </picture> </a> </p>