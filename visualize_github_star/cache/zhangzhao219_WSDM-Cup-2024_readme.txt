WSDM Cup 2024 1st Solution For Conversational Multi-Doc QA Workshop & International Challenge @ WSDM'24 - Xiaohongshu.Inc Introduction This repo contains the source code of our competition in WSDM Cup 2024: Conversational Multi-Doc QA Please refer to our paper for details Accepted by ACL 2025: Leveraging Large Language Models for Conversational Multi-Doc Question Answering: The First Place of WSDM Cup 2024 Method Overview - SOLAR-10.7B-Instruct backbone - Hybrid Training - Noisy Document Filter - Model Ensemble Environment 1. Follow Installation for modelscope/swift to install swift. 2. Install vllm 3. Install deepspeed 4. Install sklearn 5. Install SentenceTransformers Or you can run this: Tested on V100 32G with CUDA 11.8, Ubuntu 20.04.1 Main package version: Data Processing : Format data required for train and eval : For hybrid training data : Calculate scores for noisy documents filter : Interactive code to delete noisy documents Training Use LLM Framework ms-swift by ModelScope Finetuning Inference Ensemble learning : Calculate scores for ensemble learning : Ensemble results Other : Try directly generating keywords or answers by GPT : Multi Stage LLM try Not work Reproduce results on the leaderboard You can find all intermediate files in folder Prepare models 1. Download Pretrained Models From Huggingface - upstage/SOLAR-10.7B-Instruct-v1.0 10.7 B - nomic-ai/nomic-embed-text-v1 0.14 B 2. Download Our 8 Finetuned LoRA Adapters From our huggingface repository 0.03 B Each So our model size is 10.7B + 0.14B + 0.03B 8 = 11.08B, much fewer than 14 billion 14B parameters. 3. Put them in the right folder. The folder should look as follows: Inference Result Run to preprocess original test data. Then run shell script in the folder 1. You can modify CUDA device at the beginning of each shell script 2. The result files are saved in the folder, which should look as follows: Besides, the results above are as follows: | File | Word-level ROUGE-L | Character-level ROUGE-L | Keywords Recall | |--------| ---------|--------|--------| | v08-20240205-114459 | 0.45532953438881013 | 0.6143454883849857 | 0.6824189095928223 | | v10-20240205-114325 | 0.456275615214309 | 0.6149276913541135 | 0.6817805383022769 | | v13-20240202-072530 | 0.4554468517276402 | 0.6141346993379754 | 0.6827095609704305 | | v13-20240206-111010 | 0.456388581088847 | 0.6149210447203279 | 0.6840088655306036 | | v16-20240206-224659 | 0.45375515045837794 | 0.613359666771279 | 0.6879538939321544 | | v27-20240209-133614 | 0.45574561117381773 | 0.6145520850027292 | 0.6826942984551678 | | v33-20240210-002918 | 0.4559195951083145 | 0.6141543510329665 | 0.6865596963423041 | | v35-20240210-120550 | 0.45573339341665703 | 0.614208192382808 | 0.6813332802463232 | So even if they are not ensembled, each of them is still way ahead of the second place. Ensemble First, calculate the embedding score Note that this program is accelerated by , you can modify the number of processes near . It works well in V100 32G Then generate final result, It will generate in the root folder, which is our final result. | Word-level ROUGE-L | Character-level ROUGE-L | Keywords Recall | |---------|--------|--------| | 0.465360141853671 | 0.6208371209722543 | 0.6953475871954128 | Citation If you find our work helpful, please consider citing the following paper: Contacts Zhao Zhang: zhaozhao809@163.com Yiming Li: eamon.y.li@gmail.com